{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_test1_data\n",
    "from utils import gen_graph\n",
    "from utils import prepare_synthetic\n",
    "from utils import shuffle_graph\n",
    "from utils import preprocessing_data\n",
    "from utils import get_pairwise_ids\n",
    "\n",
    "from utils import prepare_test1\n",
    "from utils import top_n_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11\n",
    "SYNTHETIC_NUM = 50\n",
    "# SYNTHETIC_NUM = 1000\n",
    "\n",
    "# number of gen nodes\n",
    "# NUM_MIN = 4000\n",
    "# NUM_MAX = 4001\n",
    "NUM_MIN = 200\n",
    "NUM_MAX = 201\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "EMBEDDING_SIZE = 128\n",
    "DEPTH = 5\n",
    "BATCH_SIZE = 16\n",
    "# BATCH_SIZE = 1\n",
    "\n",
    "TEST1_NUM = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_X, test1_bc = read_test1_data(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n"
     ]
    }
   ],
   "source": [
    "train_g = gen_graph(500, 501)\n",
    "print(len(train_g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 104],\n",
       "       [100, 105],\n",
       "       [100, 107],\n",
       "       [100, 108],\n",
       "       [100, 109],\n",
       "       [100, 111],\n",
       "       [100, 113],\n",
       "       [100, 115],\n",
       "       [100, 116],\n",
       "       [100, 120]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(list(train_g.edges())) + 100)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# from model1 import DrBC\n",
    "from model import DrBC\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrBC().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DrBC(\n",
       "  (linear0): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (gcn): GCNConv()\n",
       "  (gru): GRUCell(128, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[9].grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm0 shape: torch.Size([128, 3])\n",
      "pm1 shape: torch.Size([128])\n",
      "pm2 shape: torch.Size([384, 128])\n",
      "pm3 shape: torch.Size([384, 128])\n",
      "pm4 shape: torch.Size([384])\n",
      "pm5 shape: torch.Size([384])\n",
      "pm6 shape: torch.Size([64, 128])\n",
      "pm7 shape: torch.Size([64])\n",
      "pm8 shape: torch.Size([1, 64])\n",
      "pm9 shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "pm = list(model.parameters())\n",
    "\n",
    "for i, p in enumerate(pm):\n",
    "    print(f\"pm{i} shape: {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(dict(nx.degree(train_g)).values())\n",
    "# list(dict(nx.degree(train_g)).values())\n",
    "# list(dict(nx.betweenness_centrality(train_g)).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Generating new training graph]: 100%|██████████| 50/50 [00:05<00:00,  8.83it/s]\n",
      "[Reading test1 graph]: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s]\n",
      "Epochs 0    : 100%|██████████| 3/3 [00:01<00:00,  2.42it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[239.,   1.,   1.],\n",
      "        [196.,   1.,   1.],\n",
      "        [220.,   1.,   1.],\n",
      "        [ 76.,   1.,   1.],\n",
      "        [102.,   1.,   1.]], device='cuda:0')\n",
      "tensor([0.0478, 0.0470, 0.0450, 0.0417, 0.0477], device='cuda:0')\n",
      "Val Acc: 32.0000 % | Val KendallTau: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1    : 100%|██████████| 3/3 [00:00<00:00, 50.48it/s, loss=1.11e+4]\n",
      "Epochs 2    : 100%|██████████| 3/3 [00:00<00:00, 46.86it/s, loss=1.11e+4]\n",
      "Epochs 3    : 100%|██████████| 3/3 [00:00<00:00, 49.01it/s, loss=1.11e+4]\n",
      "Epochs 4    : 100%|██████████| 3/3 [00:00<00:00, 45.84it/s, loss=1.11e+4]\n",
      "Epochs 5    : 100%|██████████| 3/3 [00:00<00:00, 48.39it/s, loss=1.11e+4]\n",
      "Epochs 6    : 100%|██████████| 3/3 [00:00<00:00, 42.79it/s, loss=1.11e+4]\n",
      "Epochs 7    : 100%|██████████| 3/3 [00:00<00:00, 51.31it/s, loss=1.11e+4]\n",
      "Epochs 8    : 100%|██████████| 3/3 [00:00<00:00, 52.05it/s, loss=1.11e+4]\n",
      "Epochs 9    : 100%|██████████| 3/3 [00:00<00:00, 52.14it/s, loss=1.11e+4]\n",
      "Epochs 10   : 100%|██████████| 3/3 [00:00<00:00, 46.95it/s, loss=1.11e+4]\n",
      "Epochs 11   : 100%|██████████| 3/3 [00:00<00:00, 45.44it/s, loss=1.11e+4]\n",
      "Epochs 12   : 100%|██████████| 3/3 [00:00<00:00, 47.10it/s, loss=1.11e+4]\n",
      "Epochs 13   : 100%|██████████| 3/3 [00:00<00:00, 48.67it/s, loss=1.11e+4]\n",
      "Epochs 14   : 100%|██████████| 3/3 [00:00<00:00, 47.90it/s, loss=1.11e+4]\n",
      "Epochs 15   : 100%|██████████| 3/3 [00:00<00:00, 49.09it/s, loss=1.11e+4]\n",
      "Epochs 16   : 100%|██████████| 3/3 [00:00<00:00, 48.27it/s, loss=1.11e+4]\n",
      "Epochs 17   : 100%|██████████| 3/3 [00:00<00:00, 44.25it/s, loss=1.11e+4]\n",
      "Epochs 18   : 100%|██████████| 3/3 [00:00<00:00, 46.95it/s, loss=1.11e+4]\n",
      "Epochs 19   : 100%|██████████| 3/3 [00:00<00:00, 48.27it/s, loss=1.11e+4]\n",
      "Epochs 20   : 100%|██████████| 3/3 [00:00<00:00, 46.61it/s, loss=1.11e+4]\n",
      "Epochs 21   : 100%|██████████| 3/3 [00:00<00:00, 46.65it/s, loss=1.11e+4]\n",
      "Epochs 22   : 100%|██████████| 3/3 [00:00<00:00, 45.77it/s, loss=1.11e+4]\n",
      "Epochs 23   : 100%|██████████| 3/3 [00:00<00:00, 49.55it/s, loss=1.11e+4]\n",
      "Epochs 24   : 100%|██████████| 3/3 [00:00<00:00, 48.37it/s, loss=1.11e+4]\n",
      "Epochs 25   : 100%|██████████| 3/3 [00:00<00:00, 47.86it/s, loss=1.11e+4]\n",
      "Epochs 26   : 100%|██████████| 3/3 [00:00<00:00, 46.09it/s, loss=1.11e+4]\n",
      "Epochs 27   : 100%|██████████| 3/3 [00:00<00:00, 48.21it/s, loss=1.11e+4]\n",
      "Epochs 28   : 100%|██████████| 3/3 [00:00<00:00, 47.14it/s, loss=1.11e+4]\n",
      "Epochs 29   : 100%|██████████| 3/3 [00:00<00:00, 47.22it/s, loss=1.11e+4]\n",
      "Epochs 30   : 100%|██████████| 3/3 [00:00<00:00, 46.52it/s, loss=1.11e+4]\n",
      "Epochs 31   : 100%|██████████| 3/3 [00:00<00:00, 46.93it/s, loss=1.11e+4]\n",
      "Epochs 32   : 100%|██████████| 3/3 [00:00<00:00, 48.60it/s, loss=1.11e+4]\n",
      "Epochs 33   : 100%|██████████| 3/3 [00:00<00:00, 48.25it/s, loss=1.11e+4]\n",
      "Epochs 34   : 100%|██████████| 3/3 [00:00<00:00, 49.76it/s, loss=1.11e+4]\n",
      "Epochs 35   : 100%|██████████| 3/3 [00:00<00:00, 41.45it/s, loss=1.11e+4]\n",
      "Epochs 36   : 100%|██████████| 3/3 [00:00<00:00, 41.76it/s, loss=1.11e+4]\n",
      "Epochs 37   : 100%|██████████| 3/3 [00:00<00:00, 43.91it/s, loss=1.11e+4]\n",
      "Epochs 38   : 100%|██████████| 3/3 [00:00<00:00, 49.00it/s, loss=1.11e+4]\n",
      "Epochs 39   : 100%|██████████| 3/3 [00:00<00:00, 46.96it/s, loss=1.11e+4]\n",
      "Epochs 40   : 100%|██████████| 3/3 [00:00<00:00, 45.66it/s, loss=1.11e+4]\n",
      "Epochs 41   : 100%|██████████| 3/3 [00:00<00:00, 47.44it/s, loss=1.11e+4]\n",
      "Epochs 42   : 100%|██████████| 3/3 [00:00<00:00, 50.82it/s, loss=1.11e+4]\n",
      "Epochs 43   : 100%|██████████| 3/3 [00:00<00:00, 47.56it/s, loss=1.11e+4]\n",
      "Epochs 44   : 100%|██████████| 3/3 [00:00<00:00, 45.44it/s, loss=1.11e+4]\n",
      "Epochs 45   : 100%|██████████| 3/3 [00:00<00:00, 45.20it/s, loss=1.11e+4]\n",
      "Epochs 46   : 100%|██████████| 3/3 [00:00<00:00, 47.13it/s, loss=1.11e+4]\n",
      "Epochs 47   : 100%|██████████| 3/3 [00:00<00:00, 48.75it/s, loss=1.11e+4]\n",
      "Epochs 48   : 100%|██████████| 3/3 [00:00<00:00, 48.94it/s, loss=1.11e+4]\n",
      "Epochs 49   : 100%|██████████| 3/3 [00:00<00:00, 44.16it/s, loss=1.11e+4]\n",
      "Epochs 50   : 100%|██████████| 3/3 [00:00<00:00, 46.55it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[239.,   1.,   1.],\n",
      "        [196.,   1.,   1.],\n",
      "        [220.,   1.,   1.],\n",
      "        [ 76.,   1.,   1.],\n",
      "        [102.,   1.,   1.]], device='cuda:0')\n",
      "tensor([0.0894, 0.0665, 0.0238, 0.0083, 0.0873], device='cuda:0')\n",
      "Val Acc: 32.0000 % | Val KendallTau: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 51   : 100%|██████████| 3/3 [00:00<00:00, 51.18it/s, loss=1.11e+4]\n",
      "Epochs 52   : 100%|██████████| 3/3 [00:00<00:00, 50.07it/s, loss=1.11e+4]\n",
      "Epochs 53   : 100%|██████████| 3/3 [00:00<00:00, 48.04it/s, loss=1.11e+4]\n",
      "Epochs 54   : 100%|██████████| 3/3 [00:00<00:00, 43.48it/s, loss=1.11e+4]\n",
      "Epochs 55   : 100%|██████████| 3/3 [00:00<00:00, 50.86it/s, loss=1.11e+4]\n",
      "Epochs 56   : 100%|██████████| 3/3 [00:00<00:00, 47.04it/s, loss=1.11e+4]\n",
      "Epochs 57   : 100%|██████████| 3/3 [00:00<00:00, 43.32it/s, loss=1.11e+4]\n",
      "Epochs 58   : 100%|██████████| 3/3 [00:00<00:00, 47.92it/s, loss=1.11e+4]\n",
      "Epochs 59   : 100%|██████████| 3/3 [00:00<00:00, 51.14it/s, loss=1.11e+4]\n",
      "Epochs 60   : 100%|██████████| 3/3 [00:00<00:00, 50.26it/s, loss=1.11e+4]\n",
      "Epochs 61   : 100%|██████████| 3/3 [00:00<00:00, 45.43it/s, loss=1.11e+4]\n",
      "Epochs 62   : 100%|██████████| 3/3 [00:00<00:00, 43.17it/s, loss=1.11e+4]\n",
      "Epochs 63   : 100%|██████████| 3/3 [00:00<00:00, 50.94it/s, loss=1.11e+4]\n",
      "Epochs 64   : 100%|██████████| 3/3 [00:00<00:00, 50.75it/s, loss=1.11e+4]\n",
      "Epochs 65   : 100%|██████████| 3/3 [00:00<00:00, 50.23it/s, loss=1.11e+4]\n",
      "Epochs 66   : 100%|██████████| 3/3 [00:00<00:00, 49.64it/s, loss=1.11e+4]\n",
      "Epochs 67   : 100%|██████████| 3/3 [00:00<00:00, 51.06it/s, loss=1.11e+4]\n",
      "Epochs 68   : 100%|██████████| 3/3 [00:00<00:00, 51.72it/s, loss=1.11e+4]\n",
      "Epochs 69   : 100%|██████████| 3/3 [00:00<00:00, 51.24it/s, loss=1.11e+4]\n",
      "Epochs 70   : 100%|██████████| 3/3 [00:00<00:00, 47.66it/s, loss=1.11e+4]\n",
      "Epochs 71   : 100%|██████████| 3/3 [00:00<00:00, 48.59it/s, loss=1.11e+4]\n",
      "Epochs 72   : 100%|██████████| 3/3 [00:00<00:00, 46.76it/s, loss=1.11e+4]\n",
      "Epochs 73   : 100%|██████████| 3/3 [00:00<00:00, 49.02it/s, loss=1.11e+4]\n",
      "Epochs 74   : 100%|██████████| 3/3 [00:00<00:00, 48.04it/s, loss=1.11e+4]\n",
      "Epochs 75   : 100%|██████████| 3/3 [00:00<00:00, 48.31it/s, loss=1.11e+4]\n",
      "Epochs 76   : 100%|██████████| 3/3 [00:00<00:00, 48.35it/s, loss=1.11e+4]\n",
      "Epochs 77   : 100%|██████████| 3/3 [00:00<00:00, 51.82it/s, loss=1.11e+4]\n",
      "Epochs 78   : 100%|██████████| 3/3 [00:00<00:00, 45.59it/s, loss=1.11e+4]\n",
      "Epochs 79   : 100%|██████████| 3/3 [00:00<00:00, 44.68it/s, loss=1.11e+4]\n",
      "Epochs 80   : 100%|██████████| 3/3 [00:00<00:00, 51.56it/s, loss=1.11e+4]\n",
      "Epochs 81   : 100%|██████████| 3/3 [00:00<00:00, 48.51it/s, loss=1.11e+4]\n",
      "Epochs 82   : 100%|██████████| 3/3 [00:00<00:00, 47.65it/s, loss=1.11e+4]\n",
      "Epochs 83   : 100%|██████████| 3/3 [00:00<00:00, 50.44it/s, loss=1.11e+4]\n",
      "Epochs 84   : 100%|██████████| 3/3 [00:00<00:00, 51.22it/s, loss=1.11e+4]\n",
      "Epochs 85   : 100%|██████████| 3/3 [00:00<00:00, 51.63it/s, loss=1.11e+4]\n",
      "Epochs 86   : 100%|██████████| 3/3 [00:00<00:00, 45.27it/s, loss=1.11e+4]\n",
      "Epochs 87   : 100%|██████████| 3/3 [00:00<00:00, 47.17it/s, loss=1.11e+4]\n",
      "Epochs 88   : 100%|██████████| 3/3 [00:00<00:00, 48.06it/s, loss=1.11e+4]\n",
      "Epochs 89   : 100%|██████████| 3/3 [00:00<00:00, 43.83it/s, loss=1.11e+4]\n",
      "Epochs 90   : 100%|██████████| 3/3 [00:00<00:00, 46.55it/s, loss=1.11e+4]\n",
      "Epochs 91   : 100%|██████████| 3/3 [00:00<00:00, 47.14it/s, loss=1.11e+4]\n",
      "Epochs 92   : 100%|██████████| 3/3 [00:00<00:00, 46.39it/s, loss=1.11e+4]\n",
      "Epochs 93   : 100%|██████████| 3/3 [00:00<00:00, 45.15it/s, loss=1.11e+4]\n",
      "Epochs 94   : 100%|██████████| 3/3 [00:00<00:00, 46.77it/s, loss=1.11e+4]\n",
      "Epochs 95   : 100%|██████████| 3/3 [00:00<00:00, 51.75it/s, loss=1.11e+4]\n",
      "Epochs 96   : 100%|██████████| 3/3 [00:00<00:00, 45.21it/s, loss=1.11e+4]\n",
      "Epochs 97   : 100%|██████████| 3/3 [00:00<00:00, 49.22it/s, loss=1.11e+4]\n",
      "Epochs 98   : 100%|██████████| 3/3 [00:00<00:00, 49.37it/s, loss=1.11e+4]\n",
      "Epochs 99   : 100%|██████████| 3/3 [00:00<00:00, 48.52it/s, loss=1.11e+4]\n",
      "Epochs 100  : 100%|██████████| 3/3 [00:00<00:00, 46.81it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[239.,   1.,   1.],\n",
      "        [196.,   1.,   1.],\n",
      "        [220.,   1.,   1.],\n",
      "        [ 76.,   1.,   1.],\n",
      "        [102.,   1.,   1.]], device='cuda:0')\n",
      "tensor([0.1346, 0.1594, 0.0733, 0.0183, 0.1245], device='cuda:0')\n",
      "Val Acc: 34.0000 % | Val KendallTau: 0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 101  : 100%|██████████| 3/3 [00:00<00:00, 41.33it/s, loss=1.11e+4]\n",
      "Epochs 102  : 100%|██████████| 3/3 [00:00<00:00, 47.87it/s, loss=1.11e+4]\n",
      "Epochs 103  : 100%|██████████| 3/3 [00:00<00:00, 51.87it/s, loss=1.11e+4]\n",
      "Epochs 104  : 100%|██████████| 3/3 [00:00<00:00, 45.08it/s, loss=1.11e+4]\n",
      "Epochs 105  : 100%|██████████| 3/3 [00:00<00:00, 45.90it/s, loss=1.11e+4]\n",
      "Epochs 106  : 100%|██████████| 3/3 [00:00<00:00, 48.33it/s, loss=1.11e+4]\n",
      "Epochs 107  : 100%|██████████| 3/3 [00:00<00:00, 47.35it/s, loss=1.11e+4]\n",
      "Epochs 108  : 100%|██████████| 3/3 [00:00<00:00, 41.61it/s, loss=1.11e+4]\n",
      "Epochs 109  : 100%|██████████| 3/3 [00:00<00:00, 50.37it/s, loss=1.11e+4]\n",
      "Epochs 110  : 100%|██████████| 3/3 [00:00<00:00, 47.39it/s, loss=1.11e+4]\n",
      "Epochs 111  : 100%|██████████| 3/3 [00:00<00:00, 49.74it/s, loss=1.11e+4]\n",
      "Epochs 112  : 100%|██████████| 3/3 [00:00<00:00, 48.44it/s, loss=1.11e+4]\n",
      "Epochs 113  : 100%|██████████| 3/3 [00:00<00:00, 47.24it/s, loss=1.11e+4]\n",
      "Epochs 114  : 100%|██████████| 3/3 [00:00<00:00, 48.23it/s, loss=1.11e+4]\n",
      "Epochs 115  : 100%|██████████| 3/3 [00:00<00:00, 49.36it/s, loss=1.11e+4]\n",
      "Epochs 116  : 100%|██████████| 3/3 [00:00<00:00, 49.23it/s, loss=1.11e+4]\n",
      "Epochs 117  : 100%|██████████| 3/3 [00:00<00:00, 44.31it/s, loss=1.11e+4]\n",
      "Epochs 118  : 100%|██████████| 3/3 [00:00<00:00, 44.52it/s, loss=1.11e+4]\n",
      "Epochs 119  : 100%|██████████| 3/3 [00:00<00:00, 47.00it/s, loss=1.11e+4]\n",
      "Epochs 120  : 100%|██████████| 3/3 [00:00<00:00, 48.23it/s, loss=1.11e+4]\n",
      "Epochs 121  : 100%|██████████| 3/3 [00:00<00:00, 49.32it/s, loss=1.11e+4]\n",
      "Epochs 122  : 100%|██████████| 3/3 [00:00<00:00, 46.00it/s, loss=1.11e+4]\n",
      "Epochs 123  : 100%|██████████| 3/3 [00:00<00:00, 48.26it/s, loss=1.11e+4]\n",
      "Epochs 124  : 100%|██████████| 3/3 [00:00<00:00, 50.59it/s, loss=1.11e+4]\n",
      "Epochs 125  : 100%|██████████| 3/3 [00:00<00:00, 48.51it/s, loss=1.11e+4]\n",
      "Epochs 126  : 100%|██████████| 3/3 [00:00<00:00, 41.47it/s, loss=1.11e+4]\n",
      "Epochs 127  : 100%|██████████| 3/3 [00:00<00:00, 49.59it/s, loss=1.11e+4]\n",
      "Epochs 128  : 100%|██████████| 3/3 [00:00<00:00, 41.40it/s, loss=1.11e+4]\n",
      "Epochs 129  : 100%|██████████| 3/3 [00:00<00:00, 47.69it/s, loss=1.11e+4]\n",
      "Epochs 130  : 100%|██████████| 3/3 [00:00<00:00, 43.30it/s, loss=1.11e+4]\n",
      "Epochs 131  : 100%|██████████| 3/3 [00:00<00:00, 47.49it/s, loss=1.11e+4]\n",
      "Epochs 132  : 100%|██████████| 3/3 [00:00<00:00, 47.88it/s, loss=1.11e+4]\n",
      "Epochs 133  : 100%|██████████| 3/3 [00:00<00:00, 49.83it/s, loss=1.11e+4]\n",
      "Epochs 134  : 100%|██████████| 3/3 [00:00<00:00, 47.54it/s, loss=1.11e+4]\n",
      "Epochs 135  : 100%|██████████| 3/3 [00:00<00:00, 48.01it/s, loss=1.11e+4]\n",
      "Epochs 136  : 100%|██████████| 3/3 [00:00<00:00, 48.89it/s, loss=1.11e+4]\n",
      "Epochs 137  : 100%|██████████| 3/3 [00:00<00:00, 48.07it/s, loss=1.11e+4]\n",
      "Epochs 138  : 100%|██████████| 3/3 [00:00<00:00, 44.93it/s, loss=1.11e+4]\n",
      "Epochs 139  : 100%|██████████| 3/3 [00:00<00:00, 47.73it/s, loss=1.11e+4]\n",
      "Epochs 140  : 100%|██████████| 3/3 [00:00<00:00, 44.74it/s, loss=1.11e+4]\n",
      "Epochs 141  : 100%|██████████| 3/3 [00:00<00:00, 48.57it/s, loss=1.11e+4]\n",
      "Epochs 142  : 100%|██████████| 3/3 [00:00<00:00, 48.53it/s, loss=1.11e+4]\n",
      "Epochs 143  : 100%|██████████| 3/3 [00:00<00:00, 43.94it/s, loss=1.11e+4]\n",
      "Epochs 144  : 100%|██████████| 3/3 [00:00<00:00, 46.25it/s, loss=1.11e+4]\n",
      "Epochs 145  : 100%|██████████| 3/3 [00:00<00:00, 45.16it/s, loss=1.11e+4]\n",
      "Epochs 146  : 100%|██████████| 3/3 [00:00<00:00, 41.83it/s, loss=1.11e+4]\n",
      "Epochs 147  : 100%|██████████| 3/3 [00:00<00:00, 49.03it/s, loss=1.11e+4]\n",
      "Epochs 148  : 100%|██████████| 3/3 [00:00<00:00, 50.74it/s, loss=1.11e+4]\n",
      "Epochs 149  : 100%|██████████| 3/3 [00:00<00:00, 51.30it/s, loss=1.11e+4]\n",
      "Epochs 150  : 100%|██████████| 3/3 [00:00<00:00, 51.20it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[239.,   1.,   1.],\n",
      "        [196.,   1.,   1.],\n",
      "        [220.,   1.,   1.],\n",
      "        [ 76.,   1.,   1.],\n",
      "        [102.,   1.,   1.]], device='cuda:0')\n",
      "tensor([0.1632, 0.1857, 0.0846, 0.0178, 0.1491], device='cuda:0')\n",
      "Val Acc: 30.0000 % | Val KendallTau: 0.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 151  : 100%|██████████| 3/3 [00:00<00:00, 49.09it/s, loss=1.11e+4]\n",
      "Epochs 152  : 100%|██████████| 3/3 [00:00<00:00, 50.36it/s, loss=1.11e+4]\n",
      "Epochs 153  : 100%|██████████| 3/3 [00:00<00:00, 49.80it/s, loss=1.11e+4]\n",
      "Epochs 154  : 100%|██████████| 3/3 [00:00<00:00, 50.94it/s, loss=1.11e+4]\n",
      "Epochs 155  : 100%|██████████| 3/3 [00:00<00:00, 53.67it/s, loss=1.11e+4]\n",
      "Epochs 156  : 100%|██████████| 3/3 [00:00<00:00, 52.21it/s, loss=1.11e+4]\n",
      "Epochs 157  : 100%|██████████| 3/3 [00:00<00:00, 49.15it/s, loss=1.11e+4]\n",
      "Epochs 158  : 100%|██████████| 3/3 [00:00<00:00, 51.43it/s, loss=1.11e+4]\n",
      "Epochs 159  : 100%|██████████| 3/3 [00:00<00:00, 50.30it/s, loss=1.11e+4]\n",
      "Epochs 160  : 100%|██████████| 3/3 [00:00<00:00, 52.91it/s, loss=1.11e+4]\n",
      "Epochs 161  : 100%|██████████| 3/3 [00:00<00:00, 49.15it/s, loss=1.11e+4]\n",
      "Epochs 162  : 100%|██████████| 3/3 [00:00<00:00, 50.44it/s, loss=1.11e+4]\n",
      "Epochs 163  : 100%|██████████| 3/3 [00:00<00:00, 49.42it/s, loss=1.11e+4]\n",
      "Epochs 164  : 100%|██████████| 3/3 [00:00<00:00, 51.26it/s, loss=1.11e+4]\n",
      "Epochs 165  : 100%|██████████| 3/3 [00:00<00:00, 51.50it/s, loss=1.11e+4]\n",
      "Epochs 166  : 100%|██████████| 3/3 [00:00<00:00, 50.45it/s, loss=1.11e+4]\n",
      "Epochs 167  : 100%|██████████| 3/3 [00:00<00:00, 51.50it/s, loss=1.11e+4]\n",
      "Epochs 168  : 100%|██████████| 3/3 [00:00<00:00, 50.88it/s, loss=1.11e+4]\n",
      "Epochs 169  : 100%|██████████| 3/3 [00:00<00:00, 53.30it/s, loss=1.11e+4]\n",
      "Epochs 170  : 100%|██████████| 3/3 [00:00<00:00, 48.96it/s, loss=1.11e+4]\n",
      "Epochs 171  : 100%|██████████| 3/3 [00:00<00:00, 50.33it/s, loss=1.11e+4]\n",
      "Epochs 172  : 100%|██████████| 3/3 [00:00<00:00, 50.06it/s, loss=1.11e+4]\n",
      "Epochs 173  : 100%|██████████| 3/3 [00:00<00:00, 50.46it/s, loss=1.11e+4]\n",
      "Epochs 174  : 100%|██████████| 3/3 [00:00<00:00, 51.79it/s, loss=1.11e+4]\n",
      "Epochs 175  : 100%|██████████| 3/3 [00:00<00:00, 51.90it/s, loss=1.11e+4]\n",
      "Epochs 176  : 100%|██████████| 3/3 [00:00<00:00, 53.28it/s, loss=1.11e+4]\n",
      "Epochs 177  : 100%|██████████| 3/3 [00:00<00:00, 50.87it/s, loss=1.11e+4]\n",
      "Epochs 178  : 100%|██████████| 3/3 [00:00<00:00, 42.86it/s, loss=1.11e+4]\n",
      "Epochs 179  : 100%|██████████| 3/3 [00:00<00:00, 47.43it/s, loss=1.11e+4]\n",
      "Epochs 180  : 100%|██████████| 3/3 [00:00<00:00, 44.25it/s, loss=1.11e+4]\n",
      "Epochs 181  : 100%|██████████| 3/3 [00:00<00:00, 42.50it/s, loss=1.11e+4]\n",
      "Epochs 182  : 100%|██████████| 3/3 [00:00<00:00, 48.05it/s, loss=1.11e+4]\n",
      "Epochs 183  : 100%|██████████| 3/3 [00:00<00:00, 44.44it/s, loss=1.11e+4]\n",
      "Epochs 184  : 100%|██████████| 3/3 [00:00<00:00, 47.80it/s, loss=1.11e+4]\n",
      "Epochs 185  : 100%|██████████| 3/3 [00:00<00:00, 50.04it/s, loss=1.11e+4]\n",
      "Epochs 186  : 100%|██████████| 3/3 [00:00<00:00, 46.91it/s, loss=1.11e+4]\n",
      "Epochs 187  : 100%|██████████| 3/3 [00:00<00:00, 47.79it/s, loss=1.11e+4]\n",
      "Epochs 188  : 100%|██████████| 3/3 [00:00<00:00, 44.62it/s, loss=1.11e+4]\n",
      "Epochs 189  : 100%|██████████| 3/3 [00:00<00:00, 48.35it/s, loss=1.11e+4]\n",
      "Epochs 190  : 100%|██████████| 3/3 [00:00<00:00, 46.47it/s, loss=1.11e+4]\n",
      "Epochs 191  : 100%|██████████| 3/3 [00:00<00:00, 49.22it/s, loss=1.11e+4]\n",
      "Epochs 192  : 100%|██████████| 3/3 [00:00<00:00, 44.86it/s, loss=1.11e+4]\n",
      "Epochs 193  : 100%|██████████| 3/3 [00:00<00:00, 45.21it/s, loss=1.11e+4]\n",
      "Epochs 194  : 100%|██████████| 3/3 [00:00<00:00, 48.93it/s, loss=1.11e+4]\n",
      "Epochs 195  : 100%|██████████| 3/3 [00:00<00:00, 49.06it/s, loss=1.11e+4]\n",
      "Epochs 196  : 100%|██████████| 3/3 [00:00<00:00, 39.37it/s, loss=1.11e+4]\n",
      "Epochs 197  : 100%|██████████| 3/3 [00:00<00:00, 48.23it/s, loss=1.11e+4]\n",
      "Epochs 198  : 100%|██████████| 3/3 [00:00<00:00, 47.47it/s, loss=1.11e+4]\n",
      "Epochs 199  : 100%|██████████| 3/3 [00:00<00:00, 47.25it/s, loss=1.11e+4]\n",
      "Epochs 200  : 100%|██████████| 3/3 [00:00<00:00, 46.61it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[239.,   1.,   1.],\n",
      "        [196.,   1.,   1.],\n",
      "        [220.,   1.,   1.],\n",
      "        [ 76.,   1.,   1.],\n",
      "        [102.,   1.,   1.]], device='cuda:0')\n",
      "tensor([0.1761, 0.1950, 0.0884, 0.0153, 0.1628], device='cuda:0')\n",
      "Val Acc: 30.0000 % | Val KendallTau: 0.1443\n"
     ]
    }
   ],
   "source": [
    "def validate(model, v_data):\n",
    "    # model.eval()\n",
    "    total_acc = 0.\n",
    "    total_kendall = 0.\n",
    "    for val_X, val_y, val_edge_index in v_data:\n",
    "        val_X, val_edge_index = val_X.to(device), val_edge_index.to(device)\n",
    "        with torch.no_grad():\n",
    "            val_y_pred = model(val_X, val_edge_index)\n",
    "\n",
    "        print('val_X: ', val_X[:5])\n",
    "        print('pred_y: ', val_y_pred[:5])\n",
    "        print('val_y: ', val_y[:5])\n",
    "        # return\n",
    "        pred_index = val_y_pred.cpu().detach().numpy().argsort()[::-1]\n",
    "        true_index = val_y.detach().numpy().argsort()[::-1]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        acc = top_n_acc(pred_index, true_index)\n",
    "        kendall_t, _ = stats.kendalltau(pred_index, true_index)\n",
    "\n",
    "        total_acc += acc\n",
    "        total_kendall += kendall_t\n",
    "\n",
    "    total_acc /= len(v_data)\n",
    "    total_kendall /= len(v_data)\n",
    "    return total_acc, total_kendall\n",
    "    \n",
    "\n",
    "def train(model, optim, loss_fn, epochs:int):\n",
    "    g_list, dg_list, bc_list  = prepare_synthetic(SYNTHETIC_NUM, (NUM_MIN, NUM_MAX))\n",
    "    v_g_list, v_dg_list, v_bc_list = prepare_test1(TEST1_NUM)\n",
    "    v_data = []\n",
    "    for i in range(TEST1_NUM):\n",
    "        val_X, val_y, val_edge_index = preprocessing_data([v_g_list[i]], [v_dg_list[i]], [v_bc_list[i]])\n",
    "        v_data.append([val_X, val_y, val_edge_index])\n",
    "\n",
    "    ls_metric = []\n",
    "    batch_cnt = len(g_list) // BATCH_SIZE\n",
    "    for e in range(epochs + 1):\n",
    "        model.train()\n",
    "        g_list, dg_list, bc_list = shuffle_graph(g_list, dg_list, bc_list)\n",
    "        batch_bar = tqdm(range(batch_cnt))\n",
    "        batch_bar.set_description(f'Epochs {e:<5}')\n",
    "        train_loss = 0\n",
    "        pair_cnt = 0\n",
    "        for i in batch_bar:\n",
    "            # batch\n",
    "            s_index, e_index = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "            train_g, train_dg, train_bc = g_list[s_index: e_index], dg_list[s_index: e_index], bc_list[s_index: e_index]\n",
    "            X, y, edge_index = preprocessing_data(train_g, train_dg, train_bc)\n",
    "            X, y, edge_index = X.to(device), y.to(device), edge_index.to(device)\n",
    "            out = model(X, edge_index)\n",
    "\n",
    "            # pairwise-loss\n",
    "            s_ids, t_ids = get_pairwise_ids(train_g)\n",
    "            out_diff = out[s_ids] - out[t_ids]\n",
    "            y_diff = y[s_ids] - y[t_ids]\n",
    "            loss = loss_fn(out_diff, torch.sigmoid(y_diff))\n",
    "\n",
    "            # optim\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            pair_cnt += s_ids.shape[0]\n",
    "            train_loss += (loss.item() * s_ids.shape[0])\n",
    "            if i == (batch_cnt - 1):\n",
    "                # last batch\n",
    "                train_loss /= pair_cnt\n",
    "                batch_bar.set_postfix(loss=round(train_loss, 6)) \n",
    "\n",
    "        if e % 50 == 0:\n",
    "            # print('out: ', out[:10])\n",
    "            val_acc, val_kendall = validate(model, v_data)\n",
    "            ls_metric.append([e, val_acc, val_kendall])\n",
    "            print(f\"Val Acc: {val_acc * 100:.4f} % | Val KendallTau: {val_kendall:.4f}\")\n",
    "        \n",
    "\n",
    "_ = train(model, optim, loss_fn, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "import urllib.request  \n",
    "\n",
    "class readFile():\n",
    "  def __init__(self,file):\n",
    "    if file == 'y':\n",
    "      url1 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/youtube/com-youtube.txt' \n",
    "      url2 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/youtube/com-youtube_score.txt' \n",
    "    else:\n",
    "      url1 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/Synthetic/5000/' + file + '.txt'\n",
    "      url2 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/Synthetic/5000/' + file + '_score.txt'\n",
    "    self.bc_value,s_list,t_list,self.deg_list,n = [],[],[],[],0\n",
    "    for line in urllib.request.urlopen(url2):\n",
    "      _,v = line.decode('utf-8').split()\n",
    "      self.bc_value.append([n,float(v)])\n",
    "      n += 1\n",
    "    for x in range(len(self.bc_value)):\n",
    "      self.deg_list.append([0,1,1])\n",
    "    for line in urllib.request.urlopen(url1):\n",
    "      s,t = line.decode('utf-8').split()\n",
    "      s,t = int(s),int(t)\n",
    "      s_list.append(s)\n",
    "      t_list.append(t)\n",
    "      self.deg_list[s][0]+=1\n",
    "      self.deg_list[t][0]+=1\n",
    "    # self.edge_index=[s_list+t_list,t_list+s_list]\n",
    "    self.edge_index=[s_list,t_list]\n",
    "\n",
    "  def get_deg_list(self):\n",
    "    # print(self.deg_list)\n",
    "    return torch.Tensor(self.deg_list).cuda()\n",
    "\n",
    "  def get_edge_index(self):\n",
    "    # print(self.edge_index)\n",
    "    return torch.tensor(self.edge_index,dtype=torch.long).cuda()\n",
    "\n",
    "  def get_bc_value(self):\n",
    "    # print(self.bc_value)\n",
    "    return self.bc_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3]) torch.Size([2, 19982])\n",
      "val_X:  tensor([[239.,   1.,   1.],\n",
      "        [178.,   1.,   1.],\n",
      "        [149.,   1.,   1.],\n",
      "        [ 90.,   1.,   1.],\n",
      "        [196.,   1.,   1.]], device='cuda:0')\n",
      "pred_y:  tensor([0.1761, 0.1734, 0.1704, 0.1547, 0.1854], device='cuda:0')\n",
      "val_y:  [[0, 0.09417453090592563], [1, 0.05397079661985897], [2, 0.04434365787783783], [3, 0.022325672571532364], [4, 0.0764376504965615]]\n",
      "0.98\n",
      "val_y:  [[0, 0.09417453090592563], [5, 0.092789552991686], [4, 0.0764376504965615], [1, 0.05397079661985897], [6, 0.05002370607942536]]\n",
      "0.888\n",
      "val_y:  [[0, 0.09417453090592563], [5, 0.092789552991686], [4, 0.0764376504965615], [1, 0.05397079661985897], [6, 0.05002370607942536]]\n",
      "0.852\n",
      "0.5481042554863033\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "f = readFile('0')\n",
    "model = model\n",
    "t = f.get_deg_list()\n",
    "t1 = f.get_edge_index()\n",
    "print(t.shape, t1.shape)\n",
    "with torch.no_grad():\n",
    "  outs = model(t,t1)\n",
    "  print('val_X: ', t[:5])\n",
    "  print('pred_y: ', outs[:5])\n",
    "\n",
    "# Top-N % accuracy\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "\n",
    "def topN_accuracy(file,outs,n):\n",
    "  predict_value,bc_value = [],[]\n",
    "  for i,j in enumerate(outs.tolist()):\n",
    "    predict_value.append([i,j])\n",
    "  bc_value = f.get_bc_value()\n",
    "  print('val_y: ', bc_value[:5])\n",
    "  bc_value.sort(key = takeSecond,reverse = True)\n",
    "  predict_value.sort(key = takeSecond,reverse = True)\n",
    "  p,t = [],[]\n",
    "  for x in range(int(len(predict_value)*n/100)):\n",
    "    p.append(predict_value[x][0])\n",
    "    t.append(bc_value[x][0])\n",
    "  # print(t)\n",
    "  # print(p)\n",
    "  return(len(set(t)&set(p)) / len(p))\n",
    "\n",
    "print(topN_accuracy(f,outs,n=1))\n",
    "print(topN_accuracy(f,outs,n=5))\n",
    "print(topN_accuracy(f,outs,n=10))\n",
    "\n",
    "# Kendall tau\n",
    "import scipy.stats as stats\n",
    "def kendall_tau(file,outs):\n",
    "  predict_value,bc_value = [],[]\n",
    "  for i,j in enumerate(outs.tolist()):\n",
    "    predict_value.append(j)\n",
    "  for i in file.get_bc_value():\n",
    "    bc_value.append(i[1])\n",
    "  # print(predict_value)\n",
    "  # print(bc_value)\n",
    "  tau, _ = stats.kendalltau(predict_value, bc_value)\n",
    "  return(tau)\n",
    "\n",
    "print(kendall_tau(f,outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[499:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = _[2]\n",
    "# g.degree(list(range(99, 105)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do List\n",
    "* (done) loss_fn 再加上 sigmoid\n",
    "* (done) pairwise 目前跨圖了\n",
    "* (done) h 要 normalized\n",
    "* (done) aggregate 改成 MessagePassing\n",
    "* (done) synthetic graph 後，shuffle graph 的順序\n",
    "* (done) 加入 Epochs\n",
    "* Metric: top1, 5, 10\n",
    "* Metric: kendall tau distance\n",
    "* wall-clock running time\n",
    "* test step\n",
    "* (done) change to leaky relu -> back to relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
