{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_test_data\n",
    "from utils import gen_graph\n",
    "from utils import prepare_synthetic\n",
    "from utils import shuffle_graph\n",
    "from utils import preprocessing_data\n",
    "from utils import get_pairwise_ids\n",
    "\n",
    "from utils import prepare_test\n",
    "from utils import top_n_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11\n",
    "SYNTHETIC_NUM = 100\n",
    "# SYNTHETIC_NUM = 1000\n",
    "\n",
    "# number of gen nodes\n",
    "# NUM_MIN = 4000\n",
    "# NUM_MAX = 4001\n",
    "NUM_MIN = 200\n",
    "NUM_MAX = 201\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "EMBEDDING_SIZE = 128\n",
    "DEPTH = 5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "TEST1_NUM = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_g, test1_bc, test1_edgeindex = read_test_data(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n"
     ]
    }
   ],
   "source": [
    "train_g = gen_graph(500, 501)\n",
    "print(len(train_g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [train_g.degree(i) for i in range(train_g.number_of_nodes())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 104],\n",
       "       [100, 105],\n",
       "       [100, 106],\n",
       "       [100, 107],\n",
       "       [100, 109],\n",
       "       [100, 110],\n",
       "       [100, 111],\n",
       "       [100, 112],\n",
       "       [100, 122],\n",
       "       [100, 130]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(list(train_g.edges())) + 100)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# from model1 import DrBC\n",
    "from model import DrBC\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrBC().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DrBC(\n",
       "  (linear0): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (gcn): GCNConv()\n",
       "  (gru): GRUCell(128, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[9].grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm0 shape: torch.Size([128, 3])\n",
      "pm1 shape: torch.Size([128])\n",
      "pm2 shape: torch.Size([384, 128])\n",
      "pm3 shape: torch.Size([384, 128])\n",
      "pm4 shape: torch.Size([384])\n",
      "pm5 shape: torch.Size([384])\n",
      "pm6 shape: torch.Size([64, 128])\n",
      "pm7 shape: torch.Size([64])\n",
      "pm8 shape: torch.Size([1, 64])\n",
      "pm9 shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "pm = list(model.parameters())\n",
    "\n",
    "for i, p in enumerate(pm):\n",
    "    print(f\"pm{i} shape: {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Generating new training graph]: 100%|██████████| 100/100 [00:11<00:00,  8.71it/s]\n",
      "[Reading test1 graph]: 100%|██████████| 30/30 [00:05<00:00,  5.18it/s]\n",
      "Epochs 0    : 100%|██████████| 6/6 [00:01<00:00,  4.73it/s, loss=0.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.2 secs\n",
      "Val Acc1: 89.40 % | Acc5: 79.45 % | Acc10: 75.87 % | Val KendallTau: 0.1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1    : 100%|██████████| 6/6 [00:00<00:00, 47.78it/s, loss=0.631]\n",
      "Epochs 2    : 100%|██████████| 6/6 [00:00<00:00, 47.12it/s, loss=0.601]\n",
      "Epochs 3    : 100%|██████████| 6/6 [00:00<00:00, 47.84it/s, loss=0.58]\n",
      "Epochs 4    : 100%|██████████| 6/6 [00:00<00:00, 47.70it/s, loss=0.564]\n",
      "Epochs 5    : 100%|██████████| 6/6 [00:00<00:00, 40.97it/s, loss=0.553]\n",
      "Epochs 6    : 100%|██████████| 6/6 [00:00<00:00, 51.45it/s, loss=0.545]\n",
      "Epochs 7    : 100%|██████████| 6/6 [00:00<00:00, 44.56it/s, loss=0.538]\n",
      "Epochs 8    : 100%|██████████| 6/6 [00:00<00:00, 45.51it/s, loss=0.533]\n",
      "Epochs 9    : 100%|██████████| 6/6 [00:00<00:00, 45.56it/s, loss=0.529]\n",
      "Epochs 10   : 100%|██████████| 6/6 [00:00<00:00, 47.60it/s, loss=0.525]\n",
      "Epochs 11   : 100%|██████████| 6/6 [00:00<00:00, 48.63it/s, loss=0.523]\n",
      "Epochs 12   : 100%|██████████| 6/6 [00:00<00:00, 44.69it/s, loss=0.521]\n",
      "Epochs 13   : 100%|██████████| 6/6 [00:00<00:00, 50.43it/s, loss=0.519]\n",
      "Epochs 14   : 100%|██████████| 6/6 [00:00<00:00, 47.61it/s, loss=0.516]\n",
      "Epochs 15   : 100%|██████████| 6/6 [00:00<00:00, 46.08it/s, loss=0.515]\n",
      "Epochs 16   : 100%|██████████| 6/6 [00:00<00:00, 44.62it/s, loss=0.514]\n",
      "Epochs 17   : 100%|██████████| 6/6 [00:00<00:00, 47.36it/s, loss=0.512]\n",
      "Epochs 18   : 100%|██████████| 6/6 [00:00<00:00, 48.10it/s, loss=0.511]\n",
      "Epochs 19   : 100%|██████████| 6/6 [00:00<00:00, 50.28it/s, loss=0.51]\n",
      "Epochs 20   : 100%|██████████| 6/6 [00:00<00:00, 45.07it/s, loss=0.509]\n",
      "Epochs 21   : 100%|██████████| 6/6 [00:00<00:00, 45.30it/s, loss=0.508]\n",
      "Epochs 22   : 100%|██████████| 6/6 [00:00<00:00, 49.09it/s, loss=0.507]\n",
      "Epochs 23   : 100%|██████████| 6/6 [00:00<00:00, 46.56it/s, loss=0.507]\n",
      "Epochs 24   : 100%|██████████| 6/6 [00:00<00:00, 47.13it/s, loss=0.507]\n",
      "Epochs 25   : 100%|██████████| 6/6 [00:00<00:00, 47.19it/s, loss=0.506]\n",
      "Epochs 26   : 100%|██████████| 6/6 [00:00<00:00, 40.71it/s, loss=0.507]\n",
      "Epochs 27   : 100%|██████████| 6/6 [00:00<00:00, 47.40it/s, loss=0.506]\n",
      "Epochs 28   : 100%|██████████| 6/6 [00:00<00:00, 50.27it/s, loss=0.506]\n",
      "Epochs 29   : 100%|██████████| 6/6 [00:00<00:00, 46.41it/s, loss=0.506]\n",
      "Epochs 30   : 100%|██████████| 6/6 [00:00<00:00, 47.89it/s, loss=0.505]\n",
      "Epochs 31   : 100%|██████████| 6/6 [00:00<00:00, 41.93it/s, loss=0.506]\n",
      "Epochs 32   : 100%|██████████| 6/6 [00:00<00:00, 50.29it/s, loss=0.506]\n",
      "Epochs 33   : 100%|██████████| 6/6 [00:00<00:00, 47.75it/s, loss=0.505]\n",
      "Epochs 34   : 100%|██████████| 6/6 [00:00<00:00, 47.20it/s, loss=0.505]\n",
      "Epochs 35   : 100%|██████████| 6/6 [00:00<00:00, 45.74it/s, loss=0.504]\n",
      "Epochs 36   : 100%|██████████| 6/6 [00:00<00:00, 48.13it/s, loss=0.504]\n",
      "Epochs 37   : 100%|██████████| 6/6 [00:00<00:00, 47.06it/s, loss=0.504]\n",
      "Epochs 38   : 100%|██████████| 6/6 [00:00<00:00, 45.99it/s, loss=0.504]\n",
      "Epochs 39   : 100%|██████████| 6/6 [00:00<00:00, 49.52it/s, loss=0.504]\n",
      "Epochs 40   : 100%|██████████| 6/6 [00:00<00:00, 45.96it/s, loss=0.504]\n",
      "Epochs 41   : 100%|██████████| 6/6 [00:00<00:00, 46.98it/s, loss=0.503]\n",
      "Epochs 42   : 100%|██████████| 6/6 [00:00<00:00, 48.57it/s, loss=0.504]\n",
      "Epochs 43   : 100%|██████████| 6/6 [00:00<00:00, 47.82it/s, loss=0.503]\n",
      "Epochs 44   : 100%|██████████| 6/6 [00:00<00:00, 49.17it/s, loss=0.503]\n",
      "Epochs 45   : 100%|██████████| 6/6 [00:00<00:00, 46.95it/s, loss=0.504]\n",
      "Epochs 46   : 100%|██████████| 6/6 [00:00<00:00, 49.19it/s, loss=0.503]\n",
      "Epochs 47   : 100%|██████████| 6/6 [00:00<00:00, 47.83it/s, loss=0.503]\n",
      "Epochs 48   : 100%|██████████| 6/6 [00:00<00:00, 47.02it/s, loss=0.503]\n",
      "Epochs 49   : 100%|██████████| 6/6 [00:00<00:00, 47.95it/s, loss=0.503]\n",
      "Epochs 50   : 100%|██████████| 6/6 [00:00<00:00, 41.82it/s, loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.2 secs\n",
      "Val Acc1: 95.80 % | Acc5: 92.93 % | Acc10: 89.57 % | Val KendallTau: 0.6204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 51   : 100%|██████████| 6/6 [00:00<00:00, 49.03it/s, loss=0.503]\n",
      "Epochs 52   : 100%|██████████| 6/6 [00:00<00:00, 49.74it/s, loss=0.502]\n",
      "Epochs 53   : 100%|██████████| 6/6 [00:00<00:00, 46.50it/s, loss=0.503]\n",
      "Epochs 54   : 100%|██████████| 6/6 [00:00<00:00, 46.39it/s, loss=0.503]\n",
      "Epochs 55   : 100%|██████████| 6/6 [00:00<00:00, 46.92it/s, loss=0.502]\n",
      "Epochs 56   : 100%|██████████| 6/6 [00:00<00:00, 44.63it/s, loss=0.501]\n",
      "Epochs 57   : 100%|██████████| 6/6 [00:00<00:00, 46.63it/s, loss=0.502]\n",
      "Epochs 58   : 100%|██████████| 6/6 [00:00<00:00, 46.95it/s, loss=0.501]\n",
      "Epochs 59   : 100%|██████████| 6/6 [00:00<00:00, 45.14it/s, loss=0.502]\n",
      "Epochs 60   : 100%|██████████| 6/6 [00:00<00:00, 46.29it/s, loss=0.501]\n",
      "Epochs 61   : 100%|██████████| 6/6 [00:00<00:00, 47.89it/s, loss=0.502]\n",
      "Epochs 62   : 100%|██████████| 6/6 [00:00<00:00, 47.59it/s, loss=0.502]\n",
      "Epochs 63   : 100%|██████████| 6/6 [00:00<00:00, 45.83it/s, loss=0.501]\n",
      "Epochs 64   : 100%|██████████| 6/6 [00:00<00:00, 48.65it/s, loss=0.501]\n",
      "Epochs 65   : 100%|██████████| 6/6 [00:00<00:00, 45.71it/s, loss=0.5]\n",
      "Epochs 66   : 100%|██████████| 6/6 [00:00<00:00, 47.86it/s, loss=0.5]\n",
      "Epochs 67   : 100%|██████████| 6/6 [00:00<00:00, 48.11it/s, loss=0.5]\n",
      "Epochs 68   : 100%|██████████| 6/6 [00:00<00:00, 47.16it/s, loss=0.5]\n",
      "Epochs 69   : 100%|██████████| 6/6 [00:00<00:00, 47.94it/s, loss=0.5]\n",
      "Epochs 70   : 100%|██████████| 6/6 [00:00<00:00, 46.12it/s, loss=0.5]\n",
      "Epochs 71   : 100%|██████████| 6/6 [00:00<00:00, 48.79it/s, loss=0.5]\n",
      "Epochs 72   : 100%|██████████| 6/6 [00:00<00:00, 49.05it/s, loss=0.5]\n",
      "Epochs 73   : 100%|██████████| 6/6 [00:00<00:00, 46.26it/s, loss=0.499]\n",
      "Epochs 74   : 100%|██████████| 6/6 [00:00<00:00, 46.39it/s, loss=0.499]\n",
      "Epochs 75   : 100%|██████████| 6/6 [00:00<00:00, 44.92it/s, loss=0.5]\n",
      "Epochs 76   : 100%|██████████| 6/6 [00:00<00:00, 48.02it/s, loss=0.5]\n",
      "Epochs 77   : 100%|██████████| 6/6 [00:00<00:00, 45.98it/s, loss=0.499]\n",
      "Epochs 78   : 100%|██████████| 6/6 [00:00<00:00, 44.16it/s, loss=0.499]\n",
      "Epochs 79   : 100%|██████████| 6/6 [00:00<00:00, 46.54it/s, loss=0.499]\n",
      "Epochs 80   : 100%|██████████| 6/6 [00:00<00:00, 47.72it/s, loss=0.5]\n",
      "Epochs 81   : 100%|██████████| 6/6 [00:00<00:00, 43.97it/s, loss=0.499]\n",
      "Epochs 82   : 100%|██████████| 6/6 [00:00<00:00, 46.82it/s, loss=0.499]\n",
      "Epochs 83   : 100%|██████████| 6/6 [00:00<00:00, 45.30it/s, loss=0.499]\n",
      "Epochs 84   : 100%|██████████| 6/6 [00:00<00:00, 45.09it/s, loss=0.5]\n",
      "Epochs 85   : 100%|██████████| 6/6 [00:00<00:00, 45.79it/s, loss=0.5]\n",
      "Epochs 86   : 100%|██████████| 6/6 [00:00<00:00, 49.58it/s, loss=0.499]\n",
      "Epochs 87   : 100%|██████████| 6/6 [00:00<00:00, 51.17it/s, loss=0.499]\n",
      "Epochs 88   : 100%|██████████| 6/6 [00:00<00:00, 44.66it/s, loss=0.499]\n",
      "Epochs 89   : 100%|██████████| 6/6 [00:00<00:00, 46.74it/s, loss=0.498]\n",
      "Epochs 90   : 100%|██████████| 6/6 [00:00<00:00, 46.25it/s, loss=0.499]\n",
      "Epochs 91   : 100%|██████████| 6/6 [00:00<00:00, 47.31it/s, loss=0.499]\n",
      "Epochs 92   : 100%|██████████| 6/6 [00:00<00:00, 50.34it/s, loss=0.5]\n",
      "Epochs 93   : 100%|██████████| 6/6 [00:00<00:00, 45.67it/s, loss=0.499]\n",
      "Epochs 94   : 100%|██████████| 6/6 [00:00<00:00, 47.49it/s, loss=0.499]\n",
      "Epochs 95   : 100%|██████████| 6/6 [00:00<00:00, 46.74it/s, loss=0.499]\n",
      "Epochs 96   : 100%|██████████| 6/6 [00:00<00:00, 48.89it/s, loss=0.499]\n",
      "Epochs 97   : 100%|██████████| 6/6 [00:00<00:00, 49.06it/s, loss=0.499]\n",
      "Epochs 98   : 100%|██████████| 6/6 [00:00<00:00, 45.06it/s, loss=0.499]\n",
      "Epochs 99   : 100%|██████████| 6/6 [00:00<00:00, 46.21it/s, loss=0.499]\n",
      "Epochs 100  : 100%|██████████| 6/6 [00:00<00:00, 48.63it/s, loss=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.2 secs\n",
      "Val Acc1: 95.80 % | Acc5: 91.95 % | Acc10: 88.62 % | Val KendallTau: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 101  : 100%|██████████| 6/6 [00:00<00:00, 47.95it/s, loss=0.498]\n",
      "Epochs 102  : 100%|██████████| 6/6 [00:00<00:00, 48.27it/s, loss=0.499]\n",
      "Epochs 103  : 100%|██████████| 6/6 [00:00<00:00, 49.94it/s, loss=0.499]\n",
      "Epochs 104  : 100%|██████████| 6/6 [00:00<00:00, 50.25it/s, loss=0.498]\n",
      "Epochs 105  : 100%|██████████| 6/6 [00:00<00:00, 49.97it/s, loss=0.498]\n",
      "Epochs 106  : 100%|██████████| 6/6 [00:00<00:00, 48.11it/s, loss=0.499]\n",
      "Epochs 107  : 100%|██████████| 6/6 [00:00<00:00, 47.43it/s, loss=0.499]\n",
      "Epochs 108  : 100%|██████████| 6/6 [00:00<00:00, 49.37it/s, loss=0.499]\n",
      "Epochs 109  : 100%|██████████| 6/6 [00:00<00:00, 47.54it/s, loss=0.499]\n",
      "Epochs 110  : 100%|██████████| 6/6 [00:00<00:00, 46.37it/s, loss=0.498]\n",
      "Epochs 111  : 100%|██████████| 6/6 [00:00<00:00, 48.81it/s, loss=0.498]\n",
      "Epochs 112  : 100%|██████████| 6/6 [00:00<00:00, 47.17it/s, loss=0.499]\n",
      "Epochs 113  : 100%|██████████| 6/6 [00:00<00:00, 45.96it/s, loss=0.499]\n",
      "Epochs 114  : 100%|██████████| 6/6 [00:00<00:00, 46.54it/s, loss=0.499]\n",
      "Epochs 115  : 100%|██████████| 6/6 [00:00<00:00, 48.09it/s, loss=0.498]\n",
      "Epochs 116  : 100%|██████████| 6/6 [00:00<00:00, 50.52it/s, loss=0.499]\n",
      "Epochs 117  : 100%|██████████| 6/6 [00:00<00:00, 48.35it/s, loss=0.498]\n",
      "Epochs 118  : 100%|██████████| 6/6 [00:00<00:00, 46.86it/s, loss=0.499]\n",
      "Epochs 119  : 100%|██████████| 6/6 [00:00<00:00, 47.87it/s, loss=0.499]\n",
      "Epochs 120  : 100%|██████████| 6/6 [00:00<00:00, 49.14it/s, loss=0.498]\n",
      "Epochs 121  : 100%|██████████| 6/6 [00:00<00:00, 51.67it/s, loss=0.499]\n",
      "Epochs 122  : 100%|██████████| 6/6 [00:00<00:00, 49.53it/s, loss=0.499]\n",
      "Epochs 123  : 100%|██████████| 6/6 [00:00<00:00, 49.87it/s, loss=0.498]\n",
      "Epochs 124  : 100%|██████████| 6/6 [00:00<00:00, 51.09it/s, loss=0.499]\n",
      "Epochs 125  : 100%|██████████| 6/6 [00:00<00:00, 49.01it/s, loss=0.499]\n",
      "Epochs 126  : 100%|██████████| 6/6 [00:00<00:00, 48.04it/s, loss=0.499]\n",
      "Epochs 127  : 100%|██████████| 6/6 [00:00<00:00, 47.53it/s, loss=0.499]\n",
      "Epochs 128  : 100%|██████████| 6/6 [00:00<00:00, 48.19it/s, loss=0.498]\n",
      "Epochs 129  : 100%|██████████| 6/6 [00:00<00:00, 50.29it/s, loss=0.499]\n",
      "Epochs 130  : 100%|██████████| 6/6 [00:00<00:00, 49.29it/s, loss=0.498]\n",
      "Epochs 131  : 100%|██████████| 6/6 [00:00<00:00, 47.21it/s, loss=0.498]\n",
      "Epochs 132  : 100%|██████████| 6/6 [00:00<00:00, 47.01it/s, loss=0.498]\n",
      "Epochs 133  : 100%|██████████| 6/6 [00:00<00:00, 43.51it/s, loss=0.499]\n",
      "Epochs 134  : 100%|██████████| 6/6 [00:00<00:00, 48.15it/s, loss=0.498]\n",
      "Epochs 135  : 100%|██████████| 6/6 [00:00<00:00, 47.44it/s, loss=0.499]\n",
      "Epochs 136  : 100%|██████████| 6/6 [00:00<00:00, 48.49it/s, loss=0.499]\n",
      "Epochs 137  : 100%|██████████| 6/6 [00:00<00:00, 46.65it/s, loss=0.499]\n",
      "Epochs 138  : 100%|██████████| 6/6 [00:00<00:00, 46.64it/s, loss=0.499]\n",
      "Epochs 139  : 100%|██████████| 6/6 [00:00<00:00, 47.03it/s, loss=0.498]\n",
      "Epochs 140  : 100%|██████████| 6/6 [00:00<00:00, 47.37it/s, loss=0.499]\n",
      "Epochs 141  : 100%|██████████| 6/6 [00:00<00:00, 48.22it/s, loss=0.499]\n",
      "Epochs 142  : 100%|██████████| 6/6 [00:00<00:00, 47.96it/s, loss=0.499]\n",
      "Epochs 143  : 100%|██████████| 6/6 [00:00<00:00, 45.38it/s, loss=0.499]\n",
      "Epochs 144  : 100%|██████████| 6/6 [00:00<00:00, 45.00it/s, loss=0.498]\n",
      "Epochs 145  : 100%|██████████| 6/6 [00:00<00:00, 48.08it/s, loss=0.498]\n",
      "Epochs 146  : 100%|██████████| 6/6 [00:00<00:00, 47.95it/s, loss=0.498]\n",
      "Epochs 147  : 100%|██████████| 6/6 [00:00<00:00, 47.91it/s, loss=0.499]\n",
      "Epochs 148  : 100%|██████████| 6/6 [00:00<00:00, 44.97it/s, loss=0.498]\n",
      "Epochs 149  : 100%|██████████| 6/6 [00:00<00:00, 45.86it/s, loss=0.499]\n",
      "Epochs 150  : 100%|██████████| 6/6 [00:00<00:00, 49.13it/s, loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.2 secs\n",
      "Val Acc1: 96.13 % | Acc5: 91.55 % | Acc10: 88.85 % | Val KendallTau: 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 151  : 100%|██████████| 6/6 [00:00<00:00, 45.09it/s, loss=0.498]\n",
      "Epochs 152  : 100%|██████████| 6/6 [00:00<00:00, 46.66it/s, loss=0.498]\n",
      "Epochs 153  : 100%|██████████| 6/6 [00:00<00:00, 49.32it/s, loss=0.499]\n",
      "Epochs 154  : 100%|██████████| 6/6 [00:00<00:00, 50.47it/s, loss=0.499]\n",
      "Epochs 155  : 100%|██████████| 6/6 [00:00<00:00, 47.48it/s, loss=0.498]\n",
      "Epochs 156  : 100%|██████████| 6/6 [00:00<00:00, 47.57it/s, loss=0.498]\n",
      "Epochs 157  : 100%|██████████| 6/6 [00:00<00:00, 47.29it/s, loss=0.499]\n",
      "Epochs 158  : 100%|██████████| 6/6 [00:00<00:00, 49.46it/s, loss=0.498]\n",
      "Epochs 159  : 100%|██████████| 6/6 [00:00<00:00, 47.39it/s, loss=0.499]\n",
      "Epochs 160  : 100%|██████████| 6/6 [00:00<00:00, 45.49it/s, loss=0.499]\n",
      "Epochs 161  : 100%|██████████| 6/6 [00:00<00:00, 46.46it/s, loss=0.499]\n",
      "Epochs 162  : 100%|██████████| 6/6 [00:00<00:00, 47.23it/s, loss=0.499]\n",
      "Epochs 163  : 100%|██████████| 6/6 [00:00<00:00, 47.47it/s, loss=0.498]\n",
      "Epochs 164  : 100%|██████████| 6/6 [00:00<00:00, 50.59it/s, loss=0.498]\n",
      "Epochs 165  : 100%|██████████| 6/6 [00:00<00:00, 47.77it/s, loss=0.499]\n",
      "Epochs 166  : 100%|██████████| 6/6 [00:00<00:00, 44.93it/s, loss=0.498]\n",
      "Epochs 167  : 100%|██████████| 6/6 [00:00<00:00, 47.16it/s, loss=0.498]\n",
      "Epochs 168  : 100%|██████████| 6/6 [00:00<00:00, 49.53it/s, loss=0.499]\n",
      "Epochs 169  : 100%|██████████| 6/6 [00:00<00:00, 48.02it/s, loss=0.498]\n",
      "Epochs 170  : 100%|██████████| 6/6 [00:00<00:00, 50.39it/s, loss=0.498]\n",
      "Epochs 171  : 100%|██████████| 6/6 [00:00<00:00, 47.09it/s, loss=0.499]\n",
      "Epochs 172  : 100%|██████████| 6/6 [00:00<00:00, 45.45it/s, loss=0.498]\n",
      "Epochs 173  : 100%|██████████| 6/6 [00:00<00:00, 47.65it/s, loss=0.498]\n",
      "Epochs 174  : 100%|██████████| 6/6 [00:00<00:00, 47.69it/s, loss=0.499]\n",
      "Epochs 175  : 100%|██████████| 6/6 [00:00<00:00, 44.92it/s, loss=0.498]\n",
      "Epochs 176  : 100%|██████████| 6/6 [00:00<00:00, 42.12it/s, loss=0.498]\n",
      "Epochs 177  : 100%|██████████| 6/6 [00:00<00:00, 43.74it/s, loss=0.498]\n",
      "Epochs 178  : 100%|██████████| 6/6 [00:00<00:00, 46.56it/s, loss=0.498]\n",
      "Epochs 179  : 100%|██████████| 6/6 [00:00<00:00, 46.25it/s, loss=0.498]\n",
      "Epochs 180  : 100%|██████████| 6/6 [00:00<00:00, 48.29it/s, loss=0.498]\n",
      "Epochs 181  : 100%|██████████| 6/6 [00:00<00:00, 45.41it/s, loss=0.498]\n",
      "Epochs 182  : 100%|██████████| 6/6 [00:00<00:00, 46.43it/s, loss=0.498]\n",
      "Epochs 183  : 100%|██████████| 6/6 [00:00<00:00, 46.96it/s, loss=0.499]\n",
      "Epochs 184  : 100%|██████████| 6/6 [00:00<00:00, 44.05it/s, loss=0.498]\n",
      "Epochs 185  : 100%|██████████| 6/6 [00:00<00:00, 48.62it/s, loss=0.498]\n",
      "Epochs 186  : 100%|██████████| 6/6 [00:00<00:00, 43.81it/s, loss=0.499]\n",
      "Epochs 187  : 100%|██████████| 6/6 [00:00<00:00, 47.51it/s, loss=0.499]\n",
      "Epochs 188  : 100%|██████████| 6/6 [00:00<00:00, 48.96it/s, loss=0.498]\n",
      "Epochs 189  : 100%|██████████| 6/6 [00:00<00:00, 46.96it/s, loss=0.498]\n",
      "Epochs 190  : 100%|██████████| 6/6 [00:00<00:00, 45.87it/s, loss=0.498]\n",
      "Epochs 191  : 100%|██████████| 6/6 [00:00<00:00, 46.08it/s, loss=0.499]\n",
      "Epochs 192  : 100%|██████████| 6/6 [00:00<00:00, 49.02it/s, loss=0.498]\n",
      "Epochs 193  : 100%|██████████| 6/6 [00:00<00:00, 48.79it/s, loss=0.498]\n",
      "Epochs 194  : 100%|██████████| 6/6 [00:00<00:00, 49.62it/s, loss=0.499]\n",
      "Epochs 195  : 100%|██████████| 6/6 [00:00<00:00, 49.97it/s, loss=0.499]\n",
      "Epochs 196  : 100%|██████████| 6/6 [00:00<00:00, 47.20it/s, loss=0.498]\n",
      "Epochs 197  : 100%|██████████| 6/6 [00:00<00:00, 48.66it/s, loss=0.499]\n",
      "Epochs 198  : 100%|██████████| 6/6 [00:00<00:00, 49.18it/s, loss=0.499]\n",
      "Epochs 199  : 100%|██████████| 6/6 [00:00<00:00, 50.01it/s, loss=0.498]\n",
      "Epochs 200  : 100%|██████████| 6/6 [00:00<00:00, 46.72it/s, loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.2 secs\n",
      "Val Acc1: 96.20 % | Acc5: 91.52 % | Acc10: 88.95 % | Val KendallTau: 0.6845\n"
     ]
    }
   ],
   "source": [
    "def validate(model, v_data):\n",
    "    model.eval()\n",
    "    total_acc1 = 0.\n",
    "    total_acc5 = 0.\n",
    "    total_acc10 = 0.\n",
    "    total_kendall = 0.\n",
    "    start_time = time.time()\n",
    "    for val_X, val_y, val_edge_index in v_data:\n",
    "        val_X, val_edge_index = val_X.to(device), val_edge_index.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_y_pred = model(val_X, val_edge_index)\n",
    "\n",
    "        val_y_pred = val_y_pred.cpu().detach().numpy().astype('float64')\n",
    "        val_y = val_y.detach().numpy().astype('float64')\n",
    "\n",
    "        pred_index = val_y_pred.argsort()[::-1]\n",
    "        true_index = val_y.argsort()[::-1]\n",
    "        \n",
    "        acc1 = top_n_acc(pred_index, true_index, n=1)\n",
    "        acc5 = top_n_acc(pred_index, true_index, n=5)\n",
    "        acc10 = top_n_acc(pred_index, true_index, n=10)\n",
    "        kendall_t, _ = stats.kendalltau(val_y_pred, val_y)\n",
    "\n",
    "        total_acc1 += acc1\n",
    "        total_acc5 += acc5\n",
    "        total_acc10 += acc10\n",
    "        total_kendall += kendall_t\n",
    "\n",
    "    total_acc1 /= len(v_data)\n",
    "    total_acc5 /= len(v_data)\n",
    "    total_acc10 /= len(v_data)\n",
    "    total_kendall /= len(v_data)\n",
    "    time_spent = round(time.time() - start_time, 1)\n",
    "    print(f'val spend: {time_spent} secs')\n",
    "    return round(total_acc1, 6), \\\n",
    "        round(total_acc5, 6), \\\n",
    "        round(total_acc10, 6), \\\n",
    "        round(total_kendall, 6), \\\n",
    "        time_spent\n",
    "    \n",
    "\n",
    "def train(model, optim, loss_fn, epochs:int):\n",
    "    g_list, dg_list, bc_list  = prepare_synthetic(SYNTHETIC_NUM, (NUM_MIN, NUM_MAX))\n",
    "    v_data = prepare_test(TEST1_NUM)\n",
    "    \n",
    "    ls_metric = []\n",
    "    batch_cnt = len(g_list) // BATCH_SIZE\n",
    "    for e in range(epochs + 1):\n",
    "        model.train()\n",
    "        g_list, dg_list, bc_list = shuffle_graph(g_list, dg_list, bc_list)\n",
    "        batch_bar = tqdm(range(batch_cnt))\n",
    "        batch_bar.set_description(f'Epochs {e:<5}')\n",
    "        train_loss = 0\n",
    "        pair_cnt = 0\n",
    "\n",
    "        for i in batch_bar:\n",
    "            # batch\n",
    "            s_index, e_index = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "            train_g, train_dg, train_bc = g_list[s_index: e_index], dg_list[s_index: e_index], bc_list[s_index: e_index]\n",
    "            X, y, edge_index = preprocessing_data(train_g, train_dg, train_bc)\n",
    "            X, y, edge_index = X.to(device), y.to(device), edge_index.to(device)\n",
    "            out = model(X, edge_index)\n",
    "\n",
    "            # pairwise-loss\n",
    "            s_ids, t_ids = get_pairwise_ids(train_g)\n",
    "            out_diff = out[s_ids] - out[t_ids]\n",
    "            y_diff = y[s_ids] - y[t_ids]\n",
    "            loss = loss_fn(out_diff, torch.sigmoid(y_diff))\n",
    "\n",
    "            # optim\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            pair_cnt += s_ids.shape[0]\n",
    "            train_loss += (loss.item() * s_ids.shape[0])\n",
    "            if i == (batch_cnt-1):\n",
    "                # last batch\n",
    "                train_loss /= pair_cnt\n",
    "                batch_bar.set_postfix(loss=train_loss)\n",
    "        if e % 50 == 0:\n",
    "            # validate\n",
    "            val_acc1, val_acc5, val_acc10, val_kendall, time_spent = validate(model, v_data)\n",
    "            ls_metric.append([e, val_acc1, val_acc5, val_acc10, val_kendall, time_spent])\n",
    "            print(f\"Val Acc1: {val_acc1 * 100:.2f} % | Acc5: {val_acc5 * 100:.2f} % | Acc10: {val_acc10 * 100:.2f} % | Val KendallTau: {val_kendall:.4f}\")\n",
    "\n",
    "_ = train(model, optim, loss_fn, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val spend: 0.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlemilk/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/scipy/stats/_stats_py.py:5218: RuntimeWarning: overflow encountered in long_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    }
   ],
   "source": [
    "t_data = prepare_test('y')\n",
    "test_acc1, test_acc5, test_acc10, test_kendall, test_spend = validate(model, t_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: \n",
      "0.615791\n",
      "0.618709\n",
      "0.643578\n",
      "kendall:  0.288244\n"
     ]
    }
   ],
   "source": [
    "print('acc: ', test_acc1, test_acc5, test_acc10, sep='\\n')\n",
    "print('kendall: ', test_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic graph num: 100\n",
    "# synthetic node num: 200\n",
    "# epoch: 200\n",
    "\n",
    "\n",
    "# with L2 norm\n",
    "# acc: \n",
    "# 0.613588\n",
    "# 0.495506\n",
    "# 0.302029\n",
    "# kendall:  -0.435382\n",
    "\n",
    "# without L2 norm + bc apply log\n",
    "# 0.615791\n",
    "# 0.618709\n",
    "# 0.643578\n",
    "# kendall:  0.288244\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.288244"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kendall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do List\n",
    "* (done) loss_fn 再加上 sigmoid\n",
    "* (done) pairwise 目前跨圖了\n",
    "* (done) h 要 normalized\n",
    "* (done) aggregate 改成 MessagePassing\n",
    "* (done) synthetic graph 後，shuffle graph 的順序\n",
    "* (done) 加入 Epochs\"\n",
    "* (done) change to leaky relu\n",
    "* Metric: top1, 5, 10\n",
    "* Metric: kendall tau distance\n",
    "* wall-clock running time\n",
    "* test step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
