{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_test1_data\n",
    "from utils import gen_graph\n",
    "from utils import prepare_synthetic\n",
    "from utils import shuffle_graph\n",
    "from utils import preprocessing_data\n",
    "from utils import get_pairwise_ids\n",
    "\n",
    "from utils import prepare_test1\n",
    "from utils import top_n_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11\n",
    "SYNTHETIC_NUM = 100\n",
    "# SYNTHETIC_NUM = 1000\n",
    "\n",
    "# number of gen nodes\n",
    "# NUM_MIN = 4000\n",
    "# NUM_MAX = 4001\n",
    "NUM_MIN = 200\n",
    "NUM_MAX = 201\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "EMBEDDING_SIZE = 128\n",
    "DEPTH = 5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "TEST1_NUM = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_g, test1_bc, test1_edgeindex = read_test1_data(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984\n"
     ]
    }
   ],
   "source": [
    "train_g = gen_graph(500, 501)\n",
    "print(len(train_g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [train_g.degree(i) for i in range(train_g.number_of_nodes())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 104],\n",
       "       [100, 105],\n",
       "       [100, 106],\n",
       "       [100, 107],\n",
       "       [100, 108],\n",
       "       [100, 109],\n",
       "       [100, 111],\n",
       "       [100, 114],\n",
       "       [100, 129],\n",
       "       [100, 131]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(list(train_g.edges())) + 100)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# from model1 import DrBC\n",
    "from model import DrBC\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrBC().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DrBC(\n",
       "  (linear0): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (gcn): GCNConv()\n",
       "  (gru): GRUCell(128, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[9].grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm0 shape: torch.Size([128, 3])\n",
      "pm1 shape: torch.Size([128])\n",
      "pm2 shape: torch.Size([384, 128])\n",
      "pm3 shape: torch.Size([384, 128])\n",
      "pm4 shape: torch.Size([384])\n",
      "pm5 shape: torch.Size([384])\n",
      "pm6 shape: torch.Size([64, 128])\n",
      "pm7 shape: torch.Size([64])\n",
      "pm8 shape: torch.Size([1, 64])\n",
      "pm9 shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "pm = list(model.parameters())\n",
    "\n",
    "for i, p in enumerate(pm):\n",
    "    print(f\"pm{i} shape: {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(dict(nx.degree(train_g)).values())\n",
    "# list(dict(nx.degree(train_g)).values())\n",
    "# list(dict(nx.betweenness_centrality(train_g)).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Generating new training graph]: 100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n",
      "[Reading test1 graph]: 100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n",
      "Epochs 0    : 100%|██████████| 6/6 [00:00<00:00, 43.54it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 87.20 % | Val KendallTau: 0.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1    : 100%|██████████| 6/6 [00:00<00:00, 44.78it/s, loss=1.11e+4]\n",
      "Epochs 2    : 100%|██████████| 6/6 [00:00<00:00, 47.34it/s, loss=1.11e+4]\n",
      "Epochs 3    : 100%|██████████| 6/6 [00:00<00:00, 42.59it/s, loss=1.11e+4]\n",
      "Epochs 4    : 100%|██████████| 6/6 [00:00<00:00, 42.26it/s, loss=1.11e+4]\n",
      "Epochs 5    : 100%|██████████| 6/6 [00:00<00:00, 43.68it/s, loss=1.11e+4]\n",
      "Epochs 6    : 100%|██████████| 6/6 [00:00<00:00, 47.21it/s, loss=1.11e+4]\n",
      "Epochs 7    : 100%|██████████| 6/6 [00:00<00:00, 42.92it/s, loss=1.11e+4]\n",
      "Epochs 8    : 100%|██████████| 6/6 [00:00<00:00, 44.06it/s, loss=1.11e+4]\n",
      "Epochs 9    : 100%|██████████| 6/6 [00:00<00:00, 43.78it/s, loss=1.11e+4]\n",
      "Epochs 10   : 100%|██████████| 6/6 [00:00<00:00, 43.98it/s, loss=1.11e+4]\n",
      "Epochs 11   : 100%|██████████| 6/6 [00:00<00:00, 42.73it/s, loss=1.11e+4]\n",
      "Epochs 12   : 100%|██████████| 6/6 [00:00<00:00, 42.62it/s, loss=1.11e+4]\n",
      "Epochs 13   : 100%|██████████| 6/6 [00:00<00:00, 45.89it/s, loss=1.11e+4]\n",
      "Epochs 14   : 100%|██████████| 6/6 [00:00<00:00, 44.73it/s, loss=1.11e+4]\n",
      "Epochs 15   : 100%|██████████| 6/6 [00:00<00:00, 44.95it/s, loss=1.11e+4]\n",
      "Epochs 16   : 100%|██████████| 6/6 [00:00<00:00, 38.41it/s, loss=1.11e+4]\n",
      "Epochs 17   : 100%|██████████| 6/6 [00:00<00:00, 37.86it/s, loss=1.11e+4]\n",
      "Epochs 18   : 100%|██████████| 6/6 [00:00<00:00, 37.88it/s, loss=1.11e+4]\n",
      "Epochs 19   : 100%|██████████| 6/6 [00:00<00:00, 44.81it/s, loss=1.11e+4]\n",
      "Epochs 20   : 100%|██████████| 6/6 [00:00<00:00, 47.71it/s, loss=1.11e+4]\n",
      "Epochs 21   : 100%|██████████| 6/6 [00:00<00:00, 46.35it/s, loss=1.11e+4]\n",
      "Epochs 22   : 100%|██████████| 6/6 [00:00<00:00, 42.35it/s, loss=1.11e+4]\n",
      "Epochs 23   : 100%|██████████| 6/6 [00:00<00:00, 43.92it/s, loss=1.11e+4]\n",
      "Epochs 24   : 100%|██████████| 6/6 [00:00<00:00, 41.70it/s, loss=1.11e+4]\n",
      "Epochs 25   : 100%|██████████| 6/6 [00:00<00:00, 39.16it/s, loss=1.11e+4]\n",
      "Epochs 26   : 100%|██████████| 6/6 [00:00<00:00, 44.76it/s, loss=1.11e+4]\n",
      "Epochs 27   : 100%|██████████| 6/6 [00:00<00:00, 45.73it/s, loss=1.11e+4]\n",
      "Epochs 28   : 100%|██████████| 6/6 [00:00<00:00, 43.90it/s, loss=1.11e+4]\n",
      "Epochs 29   : 100%|██████████| 6/6 [00:00<00:00, 44.46it/s, loss=1.11e+4]\n",
      "Epochs 30   : 100%|██████████| 6/6 [00:00<00:00, 41.52it/s, loss=1.11e+4]\n",
      "Epochs 31   : 100%|██████████| 6/6 [00:00<00:00, 42.97it/s, loss=1.11e+4]\n",
      "Epochs 32   : 100%|██████████| 6/6 [00:00<00:00, 44.21it/s, loss=1.11e+4]\n",
      "Epochs 33   : 100%|██████████| 6/6 [00:00<00:00, 43.45it/s, loss=1.11e+4]\n",
      "Epochs 34   : 100%|██████████| 6/6 [00:00<00:00, 45.53it/s, loss=1.11e+4]\n",
      "Epochs 35   : 100%|██████████| 6/6 [00:00<00:00, 49.32it/s, loss=1.11e+4]\n",
      "Epochs 36   : 100%|██████████| 6/6 [00:00<00:00, 49.17it/s, loss=1.11e+4]\n",
      "Epochs 37   : 100%|██████████| 6/6 [00:00<00:00, 52.14it/s, loss=1.11e+4]\n",
      "Epochs 38   : 100%|██████████| 6/6 [00:00<00:00, 50.17it/s, loss=1.11e+4]\n",
      "Epochs 39   : 100%|██████████| 6/6 [00:00<00:00, 45.40it/s, loss=1.11e+4]\n",
      "Epochs 40   : 100%|██████████| 6/6 [00:00<00:00, 40.77it/s, loss=1.11e+4]\n",
      "Epochs 41   : 100%|██████████| 6/6 [00:00<00:00, 41.32it/s, loss=1.11e+4]\n",
      "Epochs 42   : 100%|██████████| 6/6 [00:00<00:00, 46.18it/s, loss=1.11e+4]\n",
      "Epochs 43   : 100%|██████████| 6/6 [00:00<00:00, 45.77it/s, loss=1.11e+4]\n",
      "Epochs 44   : 100%|██████████| 6/6 [00:00<00:00, 49.46it/s, loss=1.11e+4]\n",
      "Epochs 45   : 100%|██████████| 6/6 [00:00<00:00, 46.39it/s, loss=1.11e+4]\n",
      "Epochs 46   : 100%|██████████| 6/6 [00:00<00:00, 46.06it/s, loss=1.11e+4]\n",
      "Epochs 47   : 100%|██████████| 6/6 [00:00<00:00, 50.66it/s, loss=1.11e+4]\n",
      "Epochs 48   : 100%|██████████| 6/6 [00:00<00:00, 45.58it/s, loss=1.11e+4]\n",
      "Epochs 49   : 100%|██████████| 6/6 [00:00<00:00, 43.77it/s, loss=1.11e+4]\n",
      "Epochs 50   : 100%|██████████| 6/6 [00:00<00:00, 42.66it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 94.27 % | Val KendallTau: 0.4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 51   : 100%|██████████| 6/6 [00:00<00:00, 45.31it/s, loss=1.11e+4]\n",
      "Epochs 52   : 100%|██████████| 6/6 [00:00<00:00, 46.77it/s, loss=1.11e+4]\n",
      "Epochs 53   : 100%|██████████| 6/6 [00:00<00:00, 47.58it/s, loss=1.11e+4]\n",
      "Epochs 54   : 100%|██████████| 6/6 [00:00<00:00, 45.30it/s, loss=1.11e+4]\n",
      "Epochs 55   : 100%|██████████| 6/6 [00:00<00:00, 46.18it/s, loss=1.11e+4]\n",
      "Epochs 56   : 100%|██████████| 6/6 [00:00<00:00, 43.19it/s, loss=1.11e+4]\n",
      "Epochs 57   : 100%|██████████| 6/6 [00:00<00:00, 47.44it/s, loss=1.11e+4]\n",
      "Epochs 58   : 100%|██████████| 6/6 [00:00<00:00, 41.29it/s, loss=1.11e+4]\n",
      "Epochs 59   : 100%|██████████| 6/6 [00:00<00:00, 39.49it/s, loss=1.11e+4]\n",
      "Epochs 60   : 100%|██████████| 6/6 [00:00<00:00, 44.24it/s, loss=1.11e+4]\n",
      "Epochs 61   : 100%|██████████| 6/6 [00:00<00:00, 47.53it/s, loss=1.11e+4]\n",
      "Epochs 62   : 100%|██████████| 6/6 [00:00<00:00, 41.76it/s, loss=1.11e+4]\n",
      "Epochs 63   : 100%|██████████| 6/6 [00:00<00:00, 46.94it/s, loss=1.11e+4]\n",
      "Epochs 64   : 100%|██████████| 6/6 [00:00<00:00, 43.68it/s, loss=1.11e+4]\n",
      "Epochs 65   : 100%|██████████| 6/6 [00:00<00:00, 37.55it/s, loss=1.11e+4]\n",
      "Epochs 66   : 100%|██████████| 6/6 [00:00<00:00, 43.21it/s, loss=1.11e+4]\n",
      "Epochs 67   : 100%|██████████| 6/6 [00:00<00:00, 46.31it/s, loss=1.11e+4]\n",
      "Epochs 68   : 100%|██████████| 6/6 [00:00<00:00, 45.73it/s, loss=1.11e+4]\n",
      "Epochs 69   : 100%|██████████| 6/6 [00:00<00:00, 45.27it/s, loss=1.11e+4]\n",
      "Epochs 70   : 100%|██████████| 6/6 [00:00<00:00, 48.03it/s, loss=1.11e+4]\n",
      "Epochs 71   : 100%|██████████| 6/6 [00:00<00:00, 49.35it/s, loss=1.11e+4]\n",
      "Epochs 72   : 100%|██████████| 6/6 [00:00<00:00, 44.91it/s, loss=1.11e+4]\n",
      "Epochs 73   : 100%|██████████| 6/6 [00:00<00:00, 43.21it/s, loss=1.11e+4]\n",
      "Epochs 74   : 100%|██████████| 6/6 [00:00<00:00, 39.96it/s, loss=1.11e+4]\n",
      "Epochs 75   : 100%|██████████| 6/6 [00:00<00:00, 38.03it/s, loss=1.11e+4]\n",
      "Epochs 76   : 100%|██████████| 6/6 [00:00<00:00, 42.31it/s, loss=1.11e+4]\n",
      "Epochs 77   : 100%|██████████| 6/6 [00:00<00:00, 44.52it/s, loss=1.11e+4]\n",
      "Epochs 78   : 100%|██████████| 6/6 [00:00<00:00, 43.73it/s, loss=1.11e+4]\n",
      "Epochs 79   : 100%|██████████| 6/6 [00:00<00:00, 42.82it/s, loss=1.11e+4]\n",
      "Epochs 80   : 100%|██████████| 6/6 [00:00<00:00, 44.04it/s, loss=1.11e+4]\n",
      "Epochs 81   : 100%|██████████| 6/6 [00:00<00:00, 41.94it/s, loss=1.11e+4]\n",
      "Epochs 82   : 100%|██████████| 6/6 [00:00<00:00, 45.60it/s, loss=1.11e+4]\n",
      "Epochs 83   : 100%|██████████| 6/6 [00:00<00:00, 45.18it/s, loss=1.11e+4]\n",
      "Epochs 84   : 100%|██████████| 6/6 [00:00<00:00, 46.64it/s, loss=1.11e+4]\n",
      "Epochs 85   : 100%|██████████| 6/6 [00:00<00:00, 43.54it/s, loss=1.11e+4]\n",
      "Epochs 86   : 100%|██████████| 6/6 [00:00<00:00, 44.29it/s, loss=1.11e+4]\n",
      "Epochs 87   : 100%|██████████| 6/6 [00:00<00:00, 42.59it/s, loss=1.11e+4]\n",
      "Epochs 88   : 100%|██████████| 6/6 [00:00<00:00, 42.72it/s, loss=1.11e+4]\n",
      "Epochs 89   : 100%|██████████| 6/6 [00:00<00:00, 42.11it/s, loss=1.11e+4]\n",
      "Epochs 90   : 100%|██████████| 6/6 [00:00<00:00, 42.35it/s, loss=1.11e+4]\n",
      "Epochs 91   : 100%|██████████| 6/6 [00:00<00:00, 41.48it/s, loss=1.11e+4]\n",
      "Epochs 92   : 100%|██████████| 6/6 [00:00<00:00, 46.74it/s, loss=1.11e+4]\n",
      "Epochs 93   : 100%|██████████| 6/6 [00:00<00:00, 43.66it/s, loss=1.11e+4]\n",
      "Epochs 94   : 100%|██████████| 6/6 [00:00<00:00, 44.79it/s, loss=1.11e+4]\n",
      "Epochs 95   : 100%|██████████| 6/6 [00:00<00:00, 44.12it/s, loss=1.11e+4]\n",
      "Epochs 96   : 100%|██████████| 6/6 [00:00<00:00, 47.55it/s, loss=1.11e+4]\n",
      "Epochs 97   : 100%|██████████| 6/6 [00:00<00:00, 41.98it/s, loss=1.11e+4]\n",
      "Epochs 98   : 100%|██████████| 6/6 [00:00<00:00, 44.10it/s, loss=1.11e+4]\n",
      "Epochs 99   : 100%|██████████| 6/6 [00:00<00:00, 44.96it/s, loss=1.11e+4]\n",
      "Epochs 100  : 100%|██████████| 6/6 [00:00<00:00, 40.99it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 94.33 % | Val KendallTau: 0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 101  : 100%|██████████| 6/6 [00:00<00:00, 41.10it/s, loss=1.11e+4]\n",
      "Epochs 102  : 100%|██████████| 6/6 [00:00<00:00, 42.92it/s, loss=1.11e+4]\n",
      "Epochs 103  : 100%|██████████| 6/6 [00:00<00:00, 43.68it/s, loss=1.11e+4]\n",
      "Epochs 104  : 100%|██████████| 6/6 [00:00<00:00, 39.24it/s, loss=1.11e+4]\n",
      "Epochs 105  : 100%|██████████| 6/6 [00:00<00:00, 43.75it/s, loss=1.11e+4]\n",
      "Epochs 106  : 100%|██████████| 6/6 [00:00<00:00, 44.35it/s, loss=1.11e+4]\n",
      "Epochs 107  : 100%|██████████| 6/6 [00:00<00:00, 44.25it/s, loss=1.11e+4]\n",
      "Epochs 108  : 100%|██████████| 6/6 [00:00<00:00, 40.55it/s, loss=1.11e+4]\n",
      "Epochs 109  : 100%|██████████| 6/6 [00:00<00:00, 44.07it/s, loss=1.11e+4]\n",
      "Epochs 110  : 100%|██████████| 6/6 [00:00<00:00, 43.60it/s, loss=1.11e+4]\n",
      "Epochs 111  : 100%|██████████| 6/6 [00:00<00:00, 44.05it/s, loss=1.11e+4]\n",
      "Epochs 112  : 100%|██████████| 6/6 [00:00<00:00, 43.29it/s, loss=1.11e+4]\n",
      "Epochs 113  : 100%|██████████| 6/6 [00:00<00:00, 41.85it/s, loss=1.11e+4]\n",
      "Epochs 114  : 100%|██████████| 6/6 [00:00<00:00, 40.86it/s, loss=1.11e+4]\n",
      "Epochs 115  : 100%|██████████| 6/6 [00:00<00:00, 44.44it/s, loss=1.11e+4]\n",
      "Epochs 116  : 100%|██████████| 6/6 [00:00<00:00, 43.90it/s, loss=1.11e+4]\n",
      "Epochs 117  : 100%|██████████| 6/6 [00:00<00:00, 44.32it/s, loss=1.11e+4]\n",
      "Epochs 118  : 100%|██████████| 6/6 [00:00<00:00, 45.12it/s, loss=1.11e+4]\n",
      "Epochs 119  : 100%|██████████| 6/6 [00:00<00:00, 43.00it/s, loss=1.11e+4]\n",
      "Epochs 120  : 100%|██████████| 6/6 [00:00<00:00, 44.25it/s, loss=1.11e+4]\n",
      "Epochs 121  : 100%|██████████| 6/6 [00:00<00:00, 50.15it/s, loss=1.11e+4]\n",
      "Epochs 122  : 100%|██████████| 6/6 [00:00<00:00, 45.70it/s, loss=1.11e+4]\n",
      "Epochs 123  : 100%|██████████| 6/6 [00:00<00:00, 42.16it/s, loss=1.11e+4]\n",
      "Epochs 124  : 100%|██████████| 6/6 [00:00<00:00, 40.55it/s, loss=1.11e+4]\n",
      "Epochs 125  : 100%|██████████| 6/6 [00:00<00:00, 41.69it/s, loss=1.11e+4]\n",
      "Epochs 126  : 100%|██████████| 6/6 [00:00<00:00, 43.42it/s, loss=1.11e+4]\n",
      "Epochs 127  : 100%|██████████| 6/6 [00:00<00:00, 41.72it/s, loss=1.11e+4]\n",
      "Epochs 128  : 100%|██████████| 6/6 [00:00<00:00, 37.19it/s, loss=1.11e+4]\n",
      "Epochs 129  : 100%|██████████| 6/6 [00:00<00:00, 43.19it/s, loss=1.11e+4]\n",
      "Epochs 130  : 100%|██████████| 6/6 [00:00<00:00, 44.35it/s, loss=1.11e+4]\n",
      "Epochs 131  : 100%|██████████| 6/6 [00:00<00:00, 43.53it/s, loss=1.11e+4]\n",
      "Epochs 132  : 100%|██████████| 6/6 [00:00<00:00, 41.56it/s, loss=1.11e+4]\n",
      "Epochs 133  : 100%|██████████| 6/6 [00:00<00:00, 41.74it/s, loss=1.11e+4]\n",
      "Epochs 134  : 100%|██████████| 6/6 [00:00<00:00, 45.98it/s, loss=1.11e+4]\n",
      "Epochs 135  : 100%|██████████| 6/6 [00:00<00:00, 43.63it/s, loss=1.11e+4]\n",
      "Epochs 136  : 100%|██████████| 6/6 [00:00<00:00, 43.21it/s, loss=1.11e+4]\n",
      "Epochs 137  : 100%|██████████| 6/6 [00:00<00:00, 44.78it/s, loss=1.11e+4]\n",
      "Epochs 138  : 100%|██████████| 6/6 [00:00<00:00, 43.64it/s, loss=1.11e+4]\n",
      "Epochs 139  : 100%|██████████| 6/6 [00:00<00:00, 41.41it/s, loss=1.11e+4]\n",
      "Epochs 140  : 100%|██████████| 6/6 [00:00<00:00, 43.32it/s, loss=1.11e+4]\n",
      "Epochs 141  : 100%|██████████| 6/6 [00:00<00:00, 42.70it/s, loss=1.11e+4]\n",
      "Epochs 142  : 100%|██████████| 6/6 [00:00<00:00, 42.99it/s, loss=1.11e+4]\n",
      "Epochs 143  : 100%|██████████| 6/6 [00:00<00:00, 44.02it/s, loss=1.11e+4]\n",
      "Epochs 144  : 100%|██████████| 6/6 [00:00<00:00, 41.30it/s, loss=1.11e+4]\n",
      "Epochs 145  : 100%|██████████| 6/6 [00:00<00:00, 44.41it/s, loss=1.11e+4]\n",
      "Epochs 146  : 100%|██████████| 6/6 [00:00<00:00, 43.11it/s, loss=1.11e+4]\n",
      "Epochs 147  : 100%|██████████| 6/6 [00:00<00:00, 44.88it/s, loss=1.11e+4]\n",
      "Epochs 148  : 100%|██████████| 6/6 [00:00<00:00, 46.89it/s, loss=1.11e+4]\n",
      "Epochs 149  : 100%|██████████| 6/6 [00:00<00:00, 47.54it/s, loss=1.11e+4]\n",
      "Epochs 150  : 100%|██████████| 6/6 [00:00<00:00, 46.16it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 94.27 % | Val KendallTau: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 151  : 100%|██████████| 6/6 [00:00<00:00, 39.47it/s, loss=1.11e+4]\n",
      "Epochs 152  : 100%|██████████| 6/6 [00:00<00:00, 44.13it/s, loss=1.11e+4]\n",
      "Epochs 153  : 100%|██████████| 6/6 [00:00<00:00, 42.53it/s, loss=1.11e+4]\n",
      "Epochs 154  : 100%|██████████| 6/6 [00:00<00:00, 43.35it/s, loss=1.11e+4]\n",
      "Epochs 155  : 100%|██████████| 6/6 [00:00<00:00, 39.01it/s, loss=1.11e+4]\n",
      "Epochs 156  : 100%|██████████| 6/6 [00:00<00:00, 40.54it/s, loss=1.11e+4]\n",
      "Epochs 157  : 100%|██████████| 6/6 [00:00<00:00, 44.10it/s, loss=1.11e+4]\n",
      "Epochs 158  : 100%|██████████| 6/6 [00:00<00:00, 43.80it/s, loss=1.11e+4]\n",
      "Epochs 159  : 100%|██████████| 6/6 [00:00<00:00, 44.68it/s, loss=1.11e+4]\n",
      "Epochs 160  : 100%|██████████| 6/6 [00:00<00:00, 42.46it/s, loss=1.11e+4]\n",
      "Epochs 161  : 100%|██████████| 6/6 [00:00<00:00, 44.03it/s, loss=1.11e+4]\n",
      "Epochs 162  : 100%|██████████| 6/6 [00:00<00:00, 36.59it/s, loss=1.11e+4]\n",
      "Epochs 163  : 100%|██████████| 6/6 [00:00<00:00, 43.56it/s, loss=1.11e+4]\n",
      "Epochs 164  : 100%|██████████| 6/6 [00:00<00:00, 42.68it/s, loss=1.11e+4]\n",
      "Epochs 165  : 100%|██████████| 6/6 [00:00<00:00, 41.67it/s, loss=1.11e+4]\n",
      "Epochs 166  : 100%|██████████| 6/6 [00:00<00:00, 44.36it/s, loss=1.11e+4]\n",
      "Epochs 167  : 100%|██████████| 6/6 [00:00<00:00, 41.85it/s, loss=1.11e+4]\n",
      "Epochs 168  : 100%|██████████| 6/6 [00:00<00:00, 42.78it/s, loss=1.11e+4]\n",
      "Epochs 169  : 100%|██████████| 6/6 [00:00<00:00, 43.91it/s, loss=1.11e+4]\n",
      "Epochs 170  : 100%|██████████| 6/6 [00:00<00:00, 43.28it/s, loss=1.11e+4]\n",
      "Epochs 171  : 100%|██████████| 6/6 [00:00<00:00, 44.32it/s, loss=1.11e+4]\n",
      "Epochs 172  : 100%|██████████| 6/6 [00:00<00:00, 43.27it/s, loss=1.11e+4]\n",
      "Epochs 173  : 100%|██████████| 6/6 [00:00<00:00, 42.67it/s, loss=1.11e+4]\n",
      "Epochs 174  : 100%|██████████| 6/6 [00:00<00:00, 44.60it/s, loss=1.11e+4]\n",
      "Epochs 175  : 100%|██████████| 6/6 [00:00<00:00, 46.06it/s, loss=1.11e+4]\n",
      "Epochs 176  : 100%|██████████| 6/6 [00:00<00:00, 44.01it/s, loss=1.11e+4]\n",
      "Epochs 177  : 100%|██████████| 6/6 [00:00<00:00, 44.24it/s, loss=1.11e+4]\n",
      "Epochs 178  : 100%|██████████| 6/6 [00:00<00:00, 43.47it/s, loss=1.11e+4]\n",
      "Epochs 179  : 100%|██████████| 6/6 [00:00<00:00, 45.32it/s, loss=1.11e+4]\n",
      "Epochs 180  : 100%|██████████| 6/6 [00:00<00:00, 45.00it/s, loss=1.11e+4]\n",
      "Epochs 181  : 100%|██████████| 6/6 [00:00<00:00, 44.02it/s, loss=1.11e+4]\n",
      "Epochs 182  : 100%|██████████| 6/6 [00:00<00:00, 46.60it/s, loss=1.11e+4]\n",
      "Epochs 183  : 100%|██████████| 6/6 [00:00<00:00, 46.95it/s, loss=1.11e+4]\n",
      "Epochs 184  : 100%|██████████| 6/6 [00:00<00:00, 42.38it/s, loss=1.11e+4]\n",
      "Epochs 185  : 100%|██████████| 6/6 [00:00<00:00, 46.03it/s, loss=1.11e+4]\n",
      "Epochs 186  : 100%|██████████| 6/6 [00:00<00:00, 45.88it/s, loss=1.11e+4]\n",
      "Epochs 187  : 100%|██████████| 6/6 [00:00<00:00, 41.76it/s, loss=1.11e+4]\n",
      "Epochs 188  : 100%|██████████| 6/6 [00:00<00:00, 52.30it/s, loss=1.11e+4]\n",
      "Epochs 189  : 100%|██████████| 6/6 [00:00<00:00, 45.17it/s, loss=1.11e+4]\n",
      "Epochs 190  : 100%|██████████| 6/6 [00:00<00:00, 46.24it/s, loss=1.11e+4]\n",
      "Epochs 191  : 100%|██████████| 6/6 [00:00<00:00, 44.36it/s, loss=1.11e+4]\n",
      "Epochs 192  : 100%|██████████| 6/6 [00:00<00:00, 43.78it/s, loss=1.11e+4]\n",
      "Epochs 193  : 100%|██████████| 6/6 [00:00<00:00, 44.79it/s, loss=1.11e+4]\n",
      "Epochs 194  : 100%|██████████| 6/6 [00:00<00:00, 47.30it/s, loss=1.11e+4]\n",
      "Epochs 195  : 100%|██████████| 6/6 [00:00<00:00, 45.74it/s, loss=1.11e+4]\n",
      "Epochs 196  : 100%|██████████| 6/6 [00:00<00:00, 45.41it/s, loss=1.11e+4]\n",
      "Epochs 197  : 100%|██████████| 6/6 [00:00<00:00, 46.26it/s, loss=1.11e+4]\n",
      "Epochs 198  : 100%|██████████| 6/6 [00:00<00:00, 45.65it/s, loss=1.11e+4]\n",
      "Epochs 199  : 100%|██████████| 6/6 [00:00<00:00, 45.31it/s, loss=1.11e+4]\n",
      "Epochs 200  : 100%|██████████| 6/6 [00:00<00:00, 48.50it/s, loss=1.11e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 94.27 % | Val KendallTau: 0.6705\n"
     ]
    }
   ],
   "source": [
    "def validate(model, v_data):\n",
    "    model.eval()\n",
    "    total_acc = 0.\n",
    "    total_kendall = 0.\n",
    "    for val_X, val_y, val_edge_index in v_data:\n",
    "        val_X, val_edge_index = val_X.to(device), val_edge_index.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_y_pred = model(val_X, val_edge_index)\n",
    "\n",
    "        val_y_pred = val_y_pred.cpu().detach().numpy()\n",
    "        val_y = val_y.detach().numpy()\n",
    "\n",
    "        pred_index = val_y_pred.argsort()[::-1]\n",
    "        true_index = val_y.argsort()[::-1]\n",
    "        \n",
    "        acc = top_n_acc(pred_index, true_index)\n",
    "        kendall_t, _ = stats.kendalltau(val_y_pred, val_y)\n",
    "\n",
    "        total_acc += acc\n",
    "        total_kendall += kendall_t\n",
    "\n",
    "    total_acc /= len(v_data)\n",
    "    total_kendall /= len(v_data)\n",
    "    return total_acc, total_kendall\n",
    "    \n",
    "\n",
    "def train(model, optim, loss_fn, epochs:int):\n",
    "    g_list, dg_list, bc_list  = prepare_synthetic(SYNTHETIC_NUM, (NUM_MIN, NUM_MAX))\n",
    "    v_data = prepare_test1(TEST1_NUM)\n",
    "    \n",
    "    ls_metric = []\n",
    "    batch_cnt = len(g_list) // BATCH_SIZE\n",
    "    for e in range(epochs + 1):\n",
    "        model.train()\n",
    "        g_list, dg_list, bc_list = shuffle_graph(g_list, dg_list, bc_list)\n",
    "        batch_bar = tqdm(range(batch_cnt))\n",
    "        batch_bar.set_description(f'Epochs {e:<5}')\n",
    "        train_loss = 0\n",
    "        pair_cnt = 0\n",
    "        for i in batch_bar:\n",
    "            # batch\n",
    "            s_index, e_index = i*BATCH_SIZE, (i+1)*BATCH_SIZE\n",
    "            train_g, train_dg, train_bc = g_list[s_index: e_index], dg_list[s_index: e_index], bc_list[s_index: e_index]\n",
    "            X, y, edge_index = preprocessing_data(train_g, train_dg, train_bc)\n",
    "            X, y, edge_index = X.to(device), y.to(device), edge_index.to(device)\n",
    "            out = model(X, edge_index)\n",
    "\n",
    "            # pairwise-loss\n",
    "            s_ids, t_ids = get_pairwise_ids(train_g)\n",
    "            out_diff = out[s_ids] - out[t_ids]\n",
    "            y_diff = y[s_ids] - y[t_ids]\n",
    "            loss = loss_fn(out_diff, torch.sigmoid(y_diff))\n",
    "\n",
    "            # optim\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            pair_cnt += s_ids.shape[0]\n",
    "            train_loss += (loss.item() * s_ids.shape[0])\n",
    "            if i == (batch_cnt - 1):\n",
    "                # last batch\n",
    "                train_loss /= pair_cnt\n",
    "                batch_bar.set_postfix(loss=train_loss) \n",
    "\n",
    "        if e % 50 == 0:\n",
    "            val_acc, val_kendall = validate(model, v_data)\n",
    "            ls_metric.append([e, val_acc, val_kendall])\n",
    "            print(f\"Val Acc: {val_acc * 100:.2f} % | Val KendallTau: {val_kendall:.4f}\")\n",
    "        \n",
    "\n",
    "_ = train(model, optim, loss_fn, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = _[2]\n",
    "# g.degree(list(range(99, 105)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do List\n",
    "* (done) loss_fn 再加上 sigmoid\n",
    "* (done) pairwise 目前跨圖了\n",
    "* (done) h 要 normalized\n",
    "* (done) aggregate 改成 MessagePassing\n",
    "* (done) synthetic graph 後，shuffle graph 的順序\n",
    "* (done) 加入 Epochs\n",
    "* Metric: top1, 5, 10\n",
    "* Metric: kendall tau distance\n",
    "* wall-clock running time\n",
    "* test step\n",
    "* (done) change to leaky relu -> back to relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
