{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_test_data\n",
    "from utils import gen_graph\n",
    "from utils import prepare_synthetic\n",
    "from utils import shuffle_graph\n",
    "from utils import preprocessing_data\n",
    "from utils import get_pairwise_ids\n",
    "\n",
    "from utils import prepare_test\n",
    "from utils import top_n_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11\n",
    "# SYNTHETIC_NUM = 16\n",
    "SYNTHETIC_NUM = 1000\n",
    "\n",
    "\n",
    "# number of gen nodes\n",
    "# NUM_MIN = 4000\n",
    "# NUM_MAX = 4001\n",
    "NUM_MIN = 5000\n",
    "NUM_MAX = 5001\n",
    "IS_PARALLEL = True if NUM_MIN >= 1000 else False\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "EMBEDDING_SIZE = 128\n",
    "DEPTH = 5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "TEST1_NUM = 30\n",
    "\n",
    "MODEL_SAVED_PATH = \"saved_model/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_g, test1_bc, test1_edgeindex = read_test_data(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n"
     ]
    }
   ],
   "source": [
    "train_g = gen_graph(500, 501)\n",
    "print(len(train_g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [train_g.degree(i) for i in range(train_g.number_of_nodes())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (np.array(list(train_g.edges())) + 100)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(train_g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# from model1 import DrBC\n",
    "from model import DrBC\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrBC().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DrBC(\n",
       "  (linear0): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (gcn): GCNConv()\n",
       "  (gru): GRUCell(128, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[9].grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm0 shape: torch.Size([128, 3])\n",
      "pm1 shape: torch.Size([128])\n",
      "pm2 shape: torch.Size([384, 128])\n",
      "pm3 shape: torch.Size([384, 128])\n",
      "pm4 shape: torch.Size([384])\n",
      "pm5 shape: torch.Size([384])\n",
      "pm6 shape: torch.Size([64, 128])\n",
      "pm7 shape: torch.Size([64])\n",
      "pm8 shape: torch.Size([1, 64])\n",
      "pm9 shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "pm = list(model.parameters())\n",
    "\n",
    "for i, p in enumerate(pm):\n",
    "    print(f\"pm{i} shape: {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Generating new training graph]: 100%|██████████| 1000/1000 [7:57:26<00:00, 28.65s/it] \n",
      "[Reading test1 graph]: 100%|██████████| 30/30 [00:12<00:00,  2.50it/s]\n",
      "Epochs:   0%|          | 1/10000 [00:01<5:13:57,  1.88s/it, loss=0.867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Val Acc1: 0.00 % | Acc5: 0.00 % | Acc10: 0.00 % | KendallTau: -0.6277 | spend: 0.2 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   5%|▌         | 501/10000 [02:37<55:15,  2.87it/s, loss=0.502] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500] Val Acc1: 93.27 % | Acc5: 94.49 % | Acc10: 93.57 % | KendallTau: 0.8674 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1001/10000 [05:09<52:34,  2.85it/s, loss=0.501] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000] Val Acc1: 93.73 % | Acc5: 94.69 % | Acc10: 93.75 % | KendallTau: 0.8787 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  15%|█▌        | 1501/10000 [07:37<49:23,  2.87it/s, loss=0.499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500] Val Acc1: 95.20 % | Acc5: 94.75 % | Acc10: 93.77 % | KendallTau: 0.8809 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2001/10000 [10:04<47:05,  2.83it/s, loss=0.499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000] Val Acc1: 95.80 % | Acc5: 94.71 % | Acc10: 93.75 % | KendallTau: 0.8814 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  25%|██▌       | 2501/10000 [12:31<43:21,  2.88it/s, loss=0.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500] Val Acc1: 96.20 % | Acc5: 94.67 % | Acc10: 93.79 % | KendallTau: 0.8817 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3001/10000 [14:59<41:33,  2.81it/s, loss=0.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000] Val Acc1: 96.00 % | Acc5: 94.71 % | Acc10: 93.77 % | KendallTau: 0.8820 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  35%|███▌      | 3501/10000 [17:28<38:25,  2.82it/s, loss=0.502]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500] Val Acc1: 96.13 % | Acc5: 94.71 % | Acc10: 93.77 % | KendallTau: 0.8822 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4001/10000 [19:55<35:01,  2.86it/s, loss=0.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000] Val Acc1: 96.33 % | Acc5: 94.73 % | Acc10: 93.78 % | KendallTau: 0.8823 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  45%|████▌     | 4501/10000 [22:22<32:11,  2.85it/s, loss=0.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500] Val Acc1: 96.33 % | Acc5: 94.68 % | Acc10: 93.81 % | KendallTau: 0.8825 | spend: 0.19 secs\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5000/10000 [24:55<24:55,  3.34it/s, loss=0.5]    "
     ]
    }
   ],
   "source": [
    "def validate(model, v_data):\n",
    "    model.eval()\n",
    "    total_acc1 = 0.\n",
    "    total_acc5 = 0.\n",
    "    total_acc10 = 0.\n",
    "    total_kendall = 0.\n",
    "    start_time = time.time()\n",
    "    for val_X, val_y, val_edge_index in v_data:\n",
    "        val_X, val_edge_index = val_X.to(device), val_edge_index.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_y_pred = model(val_X, val_edge_index)\n",
    "\n",
    "        val_y_pred = val_y_pred.cpu().detach().numpy()\n",
    "        val_y = val_y.detach().numpy()\n",
    "\n",
    "        pred_index = val_y_pred.argsort()[::-1]\n",
    "        true_index = val_y.argsort()[::-1]\n",
    "        \n",
    "        acc1 = top_n_acc(pred_index, true_index, n=1)\n",
    "        acc5 = top_n_acc(pred_index, true_index, n=5)\n",
    "        acc10 = top_n_acc(pred_index, true_index, n=10)\n",
    "        kendall_t, _ = stats.kendalltau(val_y_pred, val_y)\n",
    "\n",
    "        total_acc1 += acc1\n",
    "        total_acc5 += acc5\n",
    "        total_acc10 += acc10\n",
    "        total_kendall += kendall_t\n",
    "\n",
    "    total_acc1 /= len(v_data)\n",
    "    total_acc5 /= len(v_data)\n",
    "    total_acc10 /= len(v_data)\n",
    "    total_kendall /= len(v_data)\n",
    "    time_spent = time.time() - start_time\n",
    "    return round(total_acc1, 6), \\\n",
    "        round(total_acc5, 6), \\\n",
    "        round(total_acc10, 6), \\\n",
    "        round(total_kendall, 6), \\\n",
    "        round(time_spent, 2)\n",
    "    \n",
    "\n",
    "def train(model, optim, loss_fn, epochs:int):\n",
    "    g_list, dg_list, bc_list  = prepare_synthetic(SYNTHETIC_NUM, (NUM_MIN, NUM_MAX), IS_PARALLEL)\n",
    "    v_data = prepare_test(TEST1_NUM)\n",
    "    ls_metric = []\n",
    "    epoch_bar = tqdm(range(epochs), desc=\"Epochs\")\n",
    "    for e in epoch_bar:\n",
    "        if (e % 5000 == 0) and (e != 0):\n",
    "            # re generate synthetic graph\n",
    "            g_list, dg_list, bc_list  = prepare_synthetic(SYNTHETIC_NUM, (NUM_MIN, NUM_MAX), IS_PARALLEL)\n",
    "        model.train()\n",
    "        g_list, dg_list, bc_list = shuffle_graph(g_list, dg_list, bc_list)\n",
    "        train_g, train_dg, train_bc = g_list[:16], dg_list[:16], bc_list[:16]\n",
    "        X, y, edge_index = preprocessing_data(train_g, train_dg, train_bc)\n",
    "        X, y, edge_index = X.to(device), y.to(device), edge_index.to(device)\n",
    "        out = model(X, edge_index)\n",
    "\n",
    "        # pairwise-loss\n",
    "        s_ids, t_ids = get_pairwise_ids(train_g)\n",
    "        out_diff = out[s_ids] - out[t_ids]\n",
    "        y_diff = y[s_ids] - y[t_ids]\n",
    "        loss = loss_fn(out_diff, torch.sigmoid(y_diff))\n",
    "\n",
    "        # optim\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_bar.set_postfix(loss=loss.item())\n",
    "        if e % 500 == 0:\n",
    "            # validate\n",
    "            val_acc1, val_acc5, val_acc10, val_kendall, time_spent = validate(model, v_data)\n",
    "            ls_metric.append([e, val_acc1, val_acc5, val_acc10, val_kendall, time_spent])\n",
    "            print(f\"[{e}] Val Acc1: {val_acc1 * 100:.2f} % | Acc5: {val_acc5 * 100:.2f} % | Acc10: {val_acc10 * 100:.2f} % | KendallTau: {val_kendall:.4f} | spend: {time_spent} secs\")\n",
    "            print('-'*50)\n",
    "\n",
    "    # last time \n",
    "    val_acc1, val_acc5, val_acc10, val_kendall, time_spent = validate(model, v_data)\n",
    "    ls_metric.append([epochs, val_acc1, val_acc5, val_acc10, val_kendall, time_spent])\n",
    "    print(f\"[{epochs}] Val Acc1: {val_acc1 * 100:.2f} % | Acc5: {val_acc5 * 100:.2f} % | Acc10: {val_acc10 * 100:.2f} % | KendallTau: {val_kendall:.4f} | spend: {time_spent} secs\")\n",
    "    print('-'*50)\n",
    "\n",
    "    return ls_metric\n",
    "\n",
    "train_metric = train(model, optim, loss_fn, MAX_EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model / train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_acc5</th>\n",
       "      <th>val_acc10</th>\n",
       "      <th>val_kendall</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.889067</td>\n",
       "      <td>0.821933</td>\n",
       "      <td>0.438386</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.959333</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>0.671982</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.927733</td>\n",
       "      <td>0.891133</td>\n",
       "      <td>0.671589</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.895533</td>\n",
       "      <td>0.686061</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.934800</td>\n",
       "      <td>0.899667</td>\n",
       "      <td>0.701001</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.952667</td>\n",
       "      <td>0.934933</td>\n",
       "      <td>0.900133</td>\n",
       "      <td>0.703150</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.935067</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.712888</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3500</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.934933</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.931333</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>0.898933</td>\n",
       "      <td>0.713081</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4500</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.933067</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>0.704947</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.912667</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>0.899067</td>\n",
       "      <td>0.716866</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5500</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.929867</td>\n",
       "      <td>0.892733</td>\n",
       "      <td>0.707757</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.928133</td>\n",
       "      <td>0.893867</td>\n",
       "      <td>0.715650</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6500</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.890067</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.921200</td>\n",
       "      <td>0.884400</td>\n",
       "      <td>0.702523</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7500</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.918133</td>\n",
       "      <td>0.885200</td>\n",
       "      <td>0.706834</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.919333</td>\n",
       "      <td>0.887467</td>\n",
       "      <td>0.708602</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8500</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.705359</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9000</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.923067</td>\n",
       "      <td>0.893133</td>\n",
       "      <td>0.708396</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9500</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.934667</td>\n",
       "      <td>0.922800</td>\n",
       "      <td>0.893867</td>\n",
       "      <td>0.715828</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  val_acc1  val_acc5  val_acc10  val_kendall  time\n",
       "0        0  0.918667  0.889067   0.821933     0.438386  0.19\n",
       "1      500  0.959333  0.930000   0.896600     0.671982  0.19\n",
       "2     1000  0.955333  0.927733   0.891133     0.671589  0.19\n",
       "3     1500  0.946000  0.932000   0.895533     0.686061  0.19\n",
       "4     2000  0.944667  0.934800   0.899667     0.701001  0.19\n",
       "5     2500  0.952667  0.934933   0.900133     0.703150  0.19\n",
       "6     3000  0.942000  0.935067   0.901467     0.712888  0.19\n",
       "7     3500  0.932000  0.934933   0.899000     0.704082  0.19\n",
       "8     4000  0.931333  0.935333   0.898933     0.713081  0.19\n",
       "9     4500  0.930000  0.933067   0.897200     0.704947  0.19\n",
       "10    5000  0.912667  0.936800   0.899067     0.716866  0.19\n",
       "11    5500  0.918667  0.929867   0.892733     0.707757  0.19\n",
       "12    6000  0.930000  0.928133   0.893867     0.715650  0.19\n",
       "13    6500  0.947333  0.926000   0.890067     0.712318  0.19\n",
       "14    7000  0.936000  0.921200   0.884400     0.702523  0.19\n",
       "15    7500  0.934000  0.918133   0.885200     0.706834  0.19\n",
       "16    8000  0.930667  0.919333   0.887467     0.708602  0.19\n",
       "17    8500  0.932667  0.919600   0.888800     0.705359  0.19\n",
       "18    9000  0.934000  0.923067   0.893133     0.708396  0.19\n",
       "19    9500  0.932000  0.917733   0.888333     0.709652  0.19\n",
       "20   10000  0.934667  0.922800   0.893867     0.715828  0.19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saved_name = f'{MODEL_SAVED_PATH}DrBC_G{SYNTHETIC_NUM}_N{NUM_MIN}_E{MAX_EPOCHS}.pth'\n",
    "torch.save(model.state_dict(), model_saved_name)\n",
    "\n",
    "# train\n",
    "df = pd.DataFrame(train_metric, columns=['epochs', 'val_acc1', 'val_acc5', 'val_acc10', 'val_kendall', 'time'])\n",
    "df.to_csv(f\"{MODEL_SAVED_PATH}train_metrics_G{SYNTHETIC_NUM}_N{NUM_MIN}_E{MAX_EPOCHS}.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DrBC().to(device)\n",
    "model.load_state_dict(torch.load(model_saved_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlemilk/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/scipy/stats/_stats_py.py:5218: RuntimeWarning: overflow encountered in long_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    }
   ],
   "source": [
    "t_data = prepare_test('y')\n",
    "test_acc1, test_acc5, test_acc10, test_kendall, test_spend = validate(model, t_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: \n",
      "0.600546\n",
      "0.601509\n",
      "0.636026\n",
      "kendall:  0.527324\n"
     ]
    }
   ],
   "source": [
    "print('acc: ', test_acc1, test_acc5, test_acc10, sep='\\n')\n",
    "print('kendall: ', test_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc: \n",
    "# 0.600546\n",
    "# 0.601509\n",
    "# 0.636026\n",
    "# kendall:  0.527324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic graph num: 100\n",
    "# synthetic node num: 200\n",
    "# epoch: 200\n",
    "\n",
    "\n",
    "# with L2 norm\n",
    "# acc: \n",
    "# 0.613588\n",
    "# 0.495506\n",
    "# 0.302029\n",
    "# kendall:  -0.435382\n",
    "\n",
    "# without L2 norm + bc apply log\n",
    "# 0.615791\n",
    "# 0.618709\n",
    "# 0.643578\n",
    "# kendall:  0.288244\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model200 = DrBC().to(device)\n",
    "model200.load_state_dict(torch.load(f'{MODEL_SAVED_PATH}DrBC_G1000_N200_E10000.pth'))\n",
    "\n",
    "model5000 = DrBC().to(device)\n",
    "model5000.load_state_dict(torch.load(f'{MODEL_SAVED_PATH}DrBC_G1000_N5000_E10000.pth'))\n",
    "\n",
    "scales = [5000, 10000, 20000]\n",
    "ls_metrics = []\n",
    "for scale in scales:\n",
    "    print('-'*15, scale)\n",
    "    g_list, dg_list, bc_list = prepare_synthetic(30, (scale, scale+1), parallel=True)\n",
    "    for i in enumerate(range(len(g_list))):\n",
    "        test_X, test_y, test_edge_index = preprocessing_data([g_list[i]], [dg_list[i]], [bc_list[i]])\n",
    "        t_data = [test_X, test_y, test_edge_index]\n",
    "        _acc1, _acc5, _acc10, _kendall, _time = validate(model200, t_data)\n",
    "        ls_metrics.append([scale, '200', i, _acc1, _acc5, _acc10, _kendall, _time])\n",
    "\n",
    "        _acc1, _acc5, _acc10, _kendall, _time = validate(model5000, t_data)\n",
    "        ls_metrics.append([scale, '5000', i, _acc1, _acc5, _acc10, _kendall, _time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ls_metrics, columns=['scale', 'model', 'test_graph_id', 'test_acc1', 'test_acc5', 'test_acc10', 'test_kendall', 'time'])\n",
    "df.to_csv('test_scale_diff_result.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do List\n",
    "* (done) loss_fn 再加上 sigmoid\n",
    "* (done) pairwise 目前跨圖了\n",
    "* (done) h 要 normalized\n",
    "* (done) aggregate 改成 MessagePassing\n",
    "* (done) synthetic graph 後，shuffle graph 的順序\n",
    "* (done) 加入 Epochs\"\n",
    "* (done) change to leaky relu\n",
    "* Metric: top1, 5, 10\n",
    "* Metric: kendall tau distance\n",
    "* wall-clock running time\n",
    "* test step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
